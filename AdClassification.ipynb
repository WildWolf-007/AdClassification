{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C54BCOD1b41Q",
        "outputId": "dd368530-82a7-4571-c63c-877c5e779fcb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PJp4OhHib26O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import PIL\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "from pathlib import Path\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_LGid9Zb26Q",
        "outputId": "790d62b9-b61b-44f1-f46c-d9e5793223d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('/content/drive/MyDrive/AdClassification/Ad_Classification/train'),\n",
              " PosixPath('/content/drive/MyDrive/AdClassification/Ad_Classification/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "path = Path(r\"/content/drive/MyDrive/AdClassification/Ad_Classification\")\n",
        "train_dir = path / \"train\"\n",
        "test_dir = path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NsLt9TFPb26R"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose(\n",
        "    [transforms.Resize(size = (250, 250)),\n",
        "    transforms.RandomRotation(degrees= 45),\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    transforms.RandomVerticalFlip(p = 0.5),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.Resize(size = (250, 250)),\n",
        "    transforms.RandomRotation(degrees= 45),\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    transforms.RandomVerticalFlip(p = 0.5),\n",
        "    transforms.ToTensor()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8dCDEeTIb26S"
      },
      "outputs": [],
      "source": [
        "train_data =  ImageFolder(root = train_dir, transform=train_transform, target_transform=None)\n",
        "test_data =  ImageFolder(root = test_dir, transform=test_transform, target_transform=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJmdKb-cb26S",
        "outputId": "b5cbdbb9-3bb7-4acc-abdb-8aba00c05bba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset ImageFolder\n",
              "     Number of datapoints: 97\n",
              "     Root location: /content/drive/MyDrive/AdClassification/Ad_Classification/train\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(250, 250), interpolation=bilinear, max_size=None, antialias=True)\n",
              "                RandomRotation(degrees=[-45.0, 45.0], interpolation=nearest, expand=False, fill=0)\n",
              "                RandomHorizontalFlip(p=0.5)\n",
              "                RandomVerticalFlip(p=0.5)\n",
              "                ToTensor()\n",
              "            ),\n",
              " Dataset ImageFolder\n",
              "     Number of datapoints: 23\n",
              "     Root location: /content/drive/MyDrive/AdClassification/Ad_Classification/test\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(250, 250), interpolation=bilinear, max_size=None, antialias=True)\n",
              "                RandomRotation(degrees=[-45.0, 45.0], interpolation=nearest, expand=False, fill=0)\n",
              "                RandomHorizontalFlip(p=0.5)\n",
              "                RandomVerticalFlip(p=0.5)\n",
              "                ToTensor()\n",
              "            ))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEZ_o9Gbb26S",
        "outputId": "4f9f84b8-7d6e-4d95-bfb6-9b420ad0b209"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['Creative', 'Non_Creative'], {'Creative': 0, 'Non_Creative': 1})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.classes, train_data.class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvNyi5kQb26S"
      },
      "outputs": [],
      "source": [
        "data_loader = DataLoader(dataset=train_data, batch_size = 1, shuffle = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i3K-qRgob26T"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size = 1, shuffle = True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size = 1, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfRAyjpwb26T"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knMy_BmQb26T",
        "outputId": "43e7c610-10b7-4932-afa6-55f3058a81bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
              " tensor(1))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images[0], labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n8IEq8vb26T",
        "outputId": "f2fa7178-b645-4f93-8195-b70bcd556006"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 250, 250])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hsldFDsDb26T"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4iISk_pub26T"
      },
      "outputs": [],
      "source": [
        "class AdClassification(nn.Module):\n",
        "\n",
        "    def __init__(self, input_shape : int, hidden_shape:int, output_shape : int) -> None:\n",
        "        super(AdClassification, self).__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_shape, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_shape, out_channels=hidden_shape, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_shape, out_channels=hidden_shape, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_shape, out_channels=hidden_shape, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=hidden_shape*62*62*10, out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x:torch.Tensor):\n",
        "        x1 = self.block1(x)\n",
        "        x2 = self.block2(x1)\n",
        "        x3 = self.classifier(x2)\n",
        "        return x3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jinIJ_nb26U",
        "outputId": "0a2bae8d-b5f0-4bcf-afbc-8456b97e1578"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('block1.0.weight',\n",
              "              tensor([[[[ 0.1820,  0.0088,  0.1225],\n",
              "                        [-0.1496,  0.0132,  0.0261],\n",
              "                        [-0.1414, -0.0766, -0.0159]],\n",
              "              \n",
              "                       [[ 0.1090, -0.0170,  0.1077],\n",
              "                        [ 0.1360,  0.1390, -0.1017],\n",
              "                        [-0.0896,  0.1452,  0.0122]],\n",
              "              \n",
              "                       [[ 0.1617,  0.1511, -0.0010],\n",
              "                        [ 0.0482, -0.1772, -0.1638],\n",
              "                        [ 0.1898,  0.1487,  0.0761]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0641, -0.0008,  0.1467],\n",
              "                        [-0.0704, -0.0157, -0.1911],\n",
              "                        [ 0.1086,  0.0269,  0.1067]],\n",
              "              \n",
              "                       [[-0.0314,  0.1068,  0.0757],\n",
              "                        [-0.1663, -0.0010,  0.1021],\n",
              "                        [-0.1370, -0.0753, -0.1328]],\n",
              "              \n",
              "                       [[-0.0216,  0.1311,  0.1756],\n",
              "                        [-0.1912, -0.1749,  0.1364],\n",
              "                        [ 0.1769,  0.1467,  0.0902]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.1074, -0.0039,  0.1260],\n",
              "                        [-0.0050,  0.1538, -0.0542],\n",
              "                        [-0.1045, -0.1769,  0.1057]],\n",
              "              \n",
              "                       [[-0.1027,  0.1068, -0.0597],\n",
              "                        [-0.0209,  0.0369,  0.0814],\n",
              "                        [ 0.1229, -0.1553,  0.0090]],\n",
              "              \n",
              "                       [[-0.1749, -0.1348, -0.1012],\n",
              "                        [ 0.1192,  0.0170, -0.1092],\n",
              "                        [ 0.0289,  0.0542,  0.1081]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1461, -0.0361,  0.1369],\n",
              "                        [-0.1215, -0.1621, -0.1396],\n",
              "                        [ 0.1840, -0.0911, -0.0986]],\n",
              "              \n",
              "                       [[ 0.0035,  0.0618, -0.1705],\n",
              "                        [ 0.1129, -0.0912,  0.1795],\n",
              "                        [ 0.1708, -0.1076,  0.1480]],\n",
              "              \n",
              "                       [[-0.1821,  0.1316,  0.1780],\n",
              "                        [-0.0234,  0.1860, -0.1066],\n",
              "                        [-0.0240, -0.0174,  0.1836]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1588, -0.1112,  0.1803],\n",
              "                        [ 0.1321,  0.1472,  0.0984],\n",
              "                        [ 0.1447, -0.1553,  0.0526]],\n",
              "              \n",
              "                       [[ 0.0886, -0.0389,  0.1320],\n",
              "                        [-0.0656, -0.0933, -0.1903],\n",
              "                        [-0.1769, -0.1594,  0.0947]],\n",
              "              \n",
              "                       [[-0.0137,  0.0255, -0.1359],\n",
              "                        [ 0.1355, -0.1785, -0.0455],\n",
              "                        [ 0.0011, -0.0488, -0.1748]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1784, -0.1242, -0.0971],\n",
              "                        [-0.1733,  0.0351, -0.1171],\n",
              "                        [-0.0601,  0.1345, -0.0714]],\n",
              "              \n",
              "                       [[-0.0079, -0.0958, -0.0260],\n",
              "                        [ 0.0138,  0.0356, -0.0060],\n",
              "                        [ 0.1665, -0.1391,  0.0032]],\n",
              "              \n",
              "                       [[-0.0775, -0.1891, -0.1847],\n",
              "                        [ 0.1816,  0.1060, -0.1587],\n",
              "                        [-0.0171, -0.1785,  0.0689]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.1736,  0.1655, -0.0479],\n",
              "                        [ 0.0973, -0.0525,  0.0126],\n",
              "                        [-0.0484, -0.0857,  0.0671]],\n",
              "              \n",
              "                       [[ 0.1137, -0.0616,  0.1093],\n",
              "                        [-0.1366,  0.0377,  0.0408],\n",
              "                        [ 0.0568, -0.0750,  0.1716]],\n",
              "              \n",
              "                       [[-0.1028,  0.0004, -0.1799],\n",
              "                        [-0.0554, -0.0751, -0.0944],\n",
              "                        [-0.0082, -0.1558,  0.0329]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0775, -0.0937,  0.0136],\n",
              "                        [-0.0192,  0.1831,  0.1502],\n",
              "                        [ 0.0400, -0.0598, -0.0055]],\n",
              "              \n",
              "                       [[-0.1618, -0.0614,  0.0769],\n",
              "                        [-0.0513,  0.0085, -0.0109],\n",
              "                        [-0.0859, -0.0818, -0.0680]],\n",
              "              \n",
              "                       [[ 0.1708, -0.0644,  0.0380],\n",
              "                        [-0.1591, -0.0521,  0.1414],\n",
              "                        [-0.1528, -0.1219,  0.1254]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0543, -0.1510,  0.0544],\n",
              "                        [ 0.0572, -0.0639, -0.1438],\n",
              "                        [ 0.0902,  0.0952, -0.1527]],\n",
              "              \n",
              "                       [[-0.1195, -0.0075,  0.0819],\n",
              "                        [-0.0801, -0.0018, -0.1622],\n",
              "                        [-0.0246,  0.0049,  0.0325]],\n",
              "              \n",
              "                       [[-0.1360, -0.1547,  0.1634],\n",
              "                        [ 0.0117,  0.0509,  0.0118],\n",
              "                        [-0.0819,  0.0788, -0.1169]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.1908,  0.1897,  0.1867],\n",
              "                        [-0.0181,  0.0091,  0.0226],\n",
              "                        [ 0.1298,  0.0593, -0.1165]],\n",
              "              \n",
              "                       [[-0.1463,  0.1444,  0.1475],\n",
              "                        [-0.1111,  0.1448, -0.1569],\n",
              "                        [ 0.1456,  0.0609,  0.1650]],\n",
              "              \n",
              "                       [[ 0.1025, -0.1747,  0.1262],\n",
              "                        [ 0.0641,  0.1906, -0.0259],\n",
              "                        [-0.1831,  0.0364,  0.1040]]]])),\n",
              "             ('block1.0.bias',\n",
              "              tensor([-0.0817, -0.0493, -0.0887, -0.0783, -0.1338, -0.1739, -0.1351, -0.0093,\n",
              "                      -0.1416,  0.0157])),\n",
              "             ('block1.2.weight',\n",
              "              tensor([[[[-5.1657e-02, -1.0018e-01,  6.4946e-02],\n",
              "                        [ 7.4165e-03,  1.3620e-02,  9.0357e-02],\n",
              "                        [-4.0486e-02, -3.9745e-02, -2.9423e-02]],\n",
              "              \n",
              "                       [[-1.0134e-01, -6.7508e-02,  5.5366e-02],\n",
              "                        [-3.3737e-02, -7.7112e-02,  2.8835e-02],\n",
              "                        [-2.1766e-03,  2.4908e-02,  8.2844e-02]],\n",
              "              \n",
              "                       [[ 9.8310e-02,  6.5764e-02, -6.5136e-02],\n",
              "                        [-6.7967e-02,  4.1041e-02, -6.3687e-02],\n",
              "                        [-2.0502e-02,  2.9809e-02, -3.6448e-02]],\n",
              "              \n",
              "                       [[ 1.2159e-02, -1.0242e-01,  4.1762e-02],\n",
              "                        [ 7.1610e-02, -1.0027e-01, -7.3178e-02],\n",
              "                        [-1.8638e-02,  1.7629e-02,  3.4652e-02]],\n",
              "              \n",
              "                       [[ 8.6877e-02, -9.5291e-02, -5.5846e-02],\n",
              "                        [-5.1887e-02, -9.5323e-02, -1.1619e-02],\n",
              "                        [ 2.7754e-02,  5.8332e-02, -6.2030e-02]],\n",
              "              \n",
              "                       [[-1.0138e-01,  1.9471e-02, -5.3183e-03],\n",
              "                        [-2.5894e-02, -6.0016e-02, -9.7279e-02],\n",
              "                        [-9.1140e-02, -9.7170e-02,  9.2833e-02]],\n",
              "              \n",
              "                       [[-7.5151e-02, -6.6024e-02,  7.5138e-02],\n",
              "                        [-5.6737e-02, -3.1871e-03, -4.5783e-02],\n",
              "                        [-1.6414e-02,  6.2156e-02, -6.3678e-02]],\n",
              "              \n",
              "                       [[-7.4825e-02,  1.1193e-02,  9.3468e-02],\n",
              "                        [-1.8140e-02,  1.5807e-02,  8.3138e-02],\n",
              "                        [ 1.3398e-02,  4.4789e-02,  8.7525e-02]],\n",
              "              \n",
              "                       [[ 8.9294e-02,  1.1136e-03, -8.7420e-02],\n",
              "                        [-5.9487e-02,  5.8026e-02, -2.1652e-02],\n",
              "                        [ 3.7037e-02,  1.0500e-01, -4.8647e-02]],\n",
              "              \n",
              "                       [[-4.4693e-02, -2.0592e-03, -1.3025e-03],\n",
              "                        [ 6.4763e-02, -1.0187e-02,  5.0037e-02],\n",
              "                        [ 2.6070e-02, -6.5604e-02,  1.0323e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-8.3328e-02,  4.4145e-02,  9.4767e-02],\n",
              "                        [ 1.0082e-02, -8.5347e-02,  2.8684e-02],\n",
              "                        [ 2.0980e-02,  9.5406e-04,  6.3515e-04]],\n",
              "              \n",
              "                       [[ 8.1404e-02, -9.9943e-03,  1.1845e-02],\n",
              "                        [-1.3290e-02,  5.9501e-02,  1.1227e-02],\n",
              "                        [-3.5352e-02,  7.6246e-02, -6.7602e-02]],\n",
              "              \n",
              "                       [[-8.1812e-02,  5.3531e-02, -6.9318e-02],\n",
              "                        [ 3.7631e-03, -6.6988e-02, -3.4297e-02],\n",
              "                        [ 2.9498e-02, -7.4452e-02,  7.7140e-02]],\n",
              "              \n",
              "                       [[-6.0283e-02,  7.2198e-02, -2.9314e-02],\n",
              "                        [-6.5017e-02, -2.9856e-02, -7.9459e-02],\n",
              "                        [ 9.2207e-02, -6.2444e-02, -7.4855e-02]],\n",
              "              \n",
              "                       [[-3.8024e-02, -2.9136e-02, -1.1925e-02],\n",
              "                        [ 1.0237e-01,  4.7616e-02,  3.0306e-02],\n",
              "                        [ 6.7083e-02,  2.3574e-02,  8.5260e-02]],\n",
              "              \n",
              "                       [[ 6.6723e-02,  8.6961e-02,  3.9630e-02],\n",
              "                        [ 1.0470e-01, -4.1950e-02,  6.4397e-02],\n",
              "                        [ 6.8721e-02, -9.4830e-02,  3.5469e-02]],\n",
              "              \n",
              "                       [[ 1.7446e-02, -2.2412e-02, -1.7876e-03],\n",
              "                        [ 7.3037e-03,  4.2691e-02, -5.0264e-02],\n",
              "                        [-4.8783e-02,  1.0114e-01, -1.3956e-02]],\n",
              "              \n",
              "                       [[ 2.6377e-02, -8.2000e-02,  7.8739e-02],\n",
              "                        [-1.0196e-01,  1.3186e-02,  6.3881e-02],\n",
              "                        [ 8.7635e-02,  7.8806e-02,  5.9620e-02]],\n",
              "              \n",
              "                       [[ 1.0878e-02,  6.5810e-02,  3.1169e-02],\n",
              "                        [ 5.2680e-02, -2.9206e-02,  8.9115e-02],\n",
              "                        [-7.3735e-02, -5.7381e-02,  2.0010e-02]],\n",
              "              \n",
              "                       [[ 6.8453e-02, -1.1018e-02, -1.4487e-02],\n",
              "                        [ 6.5283e-02,  5.2245e-02,  1.3454e-03],\n",
              "                        [ 3.1750e-02, -4.8798e-02,  1.4095e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.0167e-01,  8.4707e-02,  5.8497e-02],\n",
              "                        [ 1.9871e-02, -3.8982e-02, -8.0619e-02],\n",
              "                        [ 9.0587e-02,  9.8952e-02, -8.1942e-02]],\n",
              "              \n",
              "                       [[ 8.9797e-02, -7.8568e-02, -5.2245e-02],\n",
              "                        [-2.9445e-03, -2.6681e-02,  6.1608e-02],\n",
              "                        [ 6.7525e-02,  9.9492e-02,  4.9733e-02]],\n",
              "              \n",
              "                       [[ 1.6739e-02, -5.5882e-02,  2.2045e-02],\n",
              "                        [-6.1705e-02, -4.0337e-02,  3.6631e-02],\n",
              "                        [ 3.6411e-02,  1.7486e-02,  1.8796e-02]],\n",
              "              \n",
              "                       [[-5.0347e-02,  1.0183e-01,  1.4590e-02],\n",
              "                        [ 5.9274e-02, -4.8891e-03,  7.3741e-02],\n",
              "                        [-5.4312e-02,  1.3890e-02, -1.0282e-01]],\n",
              "              \n",
              "                       [[-1.3967e-02,  5.8722e-02, -1.0423e-01],\n",
              "                        [ 9.8319e-02,  4.0480e-02, -2.9069e-03],\n",
              "                        [-5.9763e-02, -3.1688e-02, -2.9113e-02]],\n",
              "              \n",
              "                       [[-2.9173e-02, -8.1782e-02, -1.5494e-05],\n",
              "                        [-7.6257e-03,  1.1967e-02,  3.7204e-02],\n",
              "                        [ 4.5857e-02, -7.7393e-02, -4.5557e-02]],\n",
              "              \n",
              "                       [[-8.7205e-02, -9.8175e-02, -1.6489e-02],\n",
              "                        [ 6.7493e-02,  7.8783e-03,  9.6479e-02],\n",
              "                        [ 3.4086e-02,  1.2668e-02,  9.8723e-02]],\n",
              "              \n",
              "                       [[-5.1346e-02, -3.2343e-02,  7.7771e-02],\n",
              "                        [-3.6567e-02,  5.4326e-02,  2.7941e-02],\n",
              "                        [-1.3377e-02,  4.9262e-02, -2.1536e-02]],\n",
              "              \n",
              "                       [[ 2.5374e-02, -2.8458e-02,  4.7042e-04],\n",
              "                        [-9.5889e-02,  2.0366e-02, -7.7270e-02],\n",
              "                        [-4.0283e-02, -6.3722e-02, -7.8992e-02]],\n",
              "              \n",
              "                       [[ 8.1692e-02,  9.7834e-02,  5.5765e-02],\n",
              "                        [-1.3660e-02, -3.9757e-02, -9.4025e-02],\n",
              "                        [ 5.9853e-02,  7.6385e-02, -7.1719e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-7.2784e-02, -2.3399e-02, -2.1333e-02],\n",
              "                        [-7.9575e-02, -1.0131e-01,  6.1767e-03],\n",
              "                        [ 7.1404e-02, -3.4793e-04, -5.9721e-02]],\n",
              "              \n",
              "                       [[ 1.4161e-02,  5.7765e-02, -1.9505e-02],\n",
              "                        [ 3.3814e-02, -3.7263e-02,  3.8927e-03],\n",
              "                        [ 3.4345e-02,  4.1720e-02,  2.8040e-02]],\n",
              "              \n",
              "                       [[ 8.6294e-02,  7.5605e-02, -7.3643e-02],\n",
              "                        [ 5.0923e-02,  1.0461e-01,  7.1809e-02],\n",
              "                        [-1.5942e-02, -7.5622e-02, -6.0536e-03]],\n",
              "              \n",
              "                       [[ 2.7837e-02,  3.5447e-02, -5.1549e-02],\n",
              "                        [ 9.7934e-02,  6.8040e-02, -8.2746e-02],\n",
              "                        [-7.6646e-02,  2.0183e-02, -6.7233e-02]],\n",
              "              \n",
              "                       [[ 2.1512e-02, -2.5645e-02, -1.0345e-01],\n",
              "                        [-6.3499e-02,  7.5150e-03,  2.9960e-02],\n",
              "                        [ 3.3235e-02,  4.1338e-02,  3.4746e-02]],\n",
              "              \n",
              "                       [[-5.4276e-03,  1.2545e-02, -1.6638e-02],\n",
              "                        [ 9.7000e-02, -5.8179e-03,  4.3943e-02],\n",
              "                        [-3.0375e-02, -9.9178e-02, -7.2487e-02]],\n",
              "              \n",
              "                       [[ 7.4604e-02,  7.4379e-02,  7.4183e-02],\n",
              "                        [ 2.1185e-02,  4.1063e-02,  5.4595e-02],\n",
              "                        [-7.4988e-02,  3.9050e-02, -1.7166e-02]],\n",
              "              \n",
              "                       [[ 5.4662e-02, -1.0005e-01,  9.9599e-02],\n",
              "                        [ 8.5812e-02, -9.2618e-02,  1.6163e-02],\n",
              "                        [-9.8244e-03,  6.9257e-02,  3.2289e-02]],\n",
              "              \n",
              "                       [[ 1.0717e-02, -7.3207e-02, -4.1680e-02],\n",
              "                        [-9.4324e-02,  9.7639e-02,  7.5899e-03],\n",
              "                        [ 5.5191e-02,  4.3257e-02,  7.8891e-02]],\n",
              "              \n",
              "                       [[ 2.4338e-02,  6.9156e-03,  1.7376e-02],\n",
              "                        [-3.3968e-02, -3.4316e-02,  6.7755e-02],\n",
              "                        [-5.0105e-02, -4.9810e-02, -1.9276e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.7681e-02,  4.3986e-02, -9.0404e-02],\n",
              "                        [-8.0703e-02, -8.1812e-02, -4.0094e-03],\n",
              "                        [-2.9422e-02, -5.7940e-02, -6.2308e-02]],\n",
              "              \n",
              "                       [[ 2.7387e-02,  2.9094e-02, -8.3961e-02],\n",
              "                        [ 3.7200e-02, -9.9232e-02,  3.7778e-02],\n",
              "                        [-8.0325e-02,  3.0115e-02,  8.7156e-02]],\n",
              "              \n",
              "                       [[-5.0351e-02,  8.5509e-02, -6.2990e-02],\n",
              "                        [-8.7809e-02, -6.0322e-02,  5.5435e-02],\n",
              "                        [-3.4595e-02, -6.0397e-03,  4.5055e-02]],\n",
              "              \n",
              "                       [[ 1.0349e-01, -3.8397e-02,  1.3449e-02],\n",
              "                        [ 2.2461e-02,  3.3939e-02, -5.4640e-02],\n",
              "                        [ 3.6695e-02,  9.6493e-03, -9.1536e-02]],\n",
              "              \n",
              "                       [[-6.3778e-02, -6.3511e-02,  6.4337e-02],\n",
              "                        [-6.4411e-02, -1.1192e-02, -4.0198e-02],\n",
              "                        [-7.0667e-02,  7.1521e-02,  9.0742e-02]],\n",
              "              \n",
              "                       [[ 6.0345e-02,  2.7647e-02, -1.0493e-01],\n",
              "                        [-5.1614e-03, -6.5005e-02, -4.1164e-02],\n",
              "                        [-6.1104e-03, -3.7142e-02, -1.8362e-02]],\n",
              "              \n",
              "                       [[-9.5831e-02, -5.3180e-02, -2.4831e-02],\n",
              "                        [-7.4393e-02,  1.0312e-01, -8.6849e-02],\n",
              "                        [-5.5774e-02, -7.3847e-02, -6.0097e-02]],\n",
              "              \n",
              "                       [[ 6.0253e-02, -4.0869e-02,  6.0366e-02],\n",
              "                        [-7.0785e-02, -3.2293e-02, -1.0122e-01],\n",
              "                        [ 8.6281e-02, -4.5589e-02, -1.8279e-02]],\n",
              "              \n",
              "                       [[-6.0402e-04,  3.6462e-02,  3.5227e-02],\n",
              "                        [-9.8666e-02,  2.3650e-02, -3.1904e-02],\n",
              "                        [ 1.6266e-02,  7.2580e-02,  2.1614e-02]],\n",
              "              \n",
              "                       [[-9.4007e-02,  6.5061e-02, -4.3865e-02],\n",
              "                        [-9.8036e-02,  6.9432e-02, -8.7712e-02],\n",
              "                        [ 7.1609e-02,  9.1666e-02,  4.4543e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.1683e-02,  6.3538e-02,  7.6520e-02],\n",
              "                        [ 1.6208e-02, -5.4949e-02,  9.0788e-02],\n",
              "                        [-1.0749e-02, -5.7717e-02, -8.9227e-02]],\n",
              "              \n",
              "                       [[ 2.0089e-02,  9.7841e-02,  5.3175e-02],\n",
              "                        [ 9.2291e-02,  1.0127e-01,  1.4833e-03],\n",
              "                        [-1.0012e-01,  1.4546e-02,  1.4129e-02]],\n",
              "              \n",
              "                       [[-6.4241e-02,  5.6755e-02, -1.6812e-02],\n",
              "                        [ 2.6278e-02,  1.0241e-01, -2.1944e-03],\n",
              "                        [-5.9249e-02, -2.1500e-02,  8.7206e-02]],\n",
              "              \n",
              "                       [[-3.2346e-02,  2.9162e-02, -1.0260e-01],\n",
              "                        [ 5.9885e-02, -2.0087e-03, -1.8979e-02],\n",
              "                        [-4.8911e-02,  4.4279e-02, -3.9721e-02]],\n",
              "              \n",
              "                       [[-6.2023e-02,  1.0173e-01,  9.9020e-02],\n",
              "                        [-6.4201e-02, -9.6990e-02, -2.9914e-02],\n",
              "                        [ 9.1024e-02,  8.9748e-02,  7.3536e-02]],\n",
              "              \n",
              "                       [[-1.0103e-01,  2.6680e-02,  4.6921e-02],\n",
              "                        [-2.6309e-02,  5.8251e-02, -7.3342e-02],\n",
              "                        [ 9.7968e-02,  5.6591e-02,  2.6746e-03]],\n",
              "              \n",
              "                       [[ 4.5072e-04, -2.7887e-02,  9.2654e-02],\n",
              "                        [ 3.2325e-02, -6.3818e-02, -4.9833e-02],\n",
              "                        [-6.4407e-02, -3.1912e-02,  4.8843e-02]],\n",
              "              \n",
              "                       [[ 6.0770e-02, -3.3260e-03,  2.4916e-02],\n",
              "                        [ 4.5512e-02, -2.4676e-02,  5.2131e-03],\n",
              "                        [-3.4559e-03,  1.0933e-02, -6.2681e-02]],\n",
              "              \n",
              "                       [[-5.5561e-02, -4.2769e-02, -9.9094e-02],\n",
              "                        [ 9.3643e-02, -7.5827e-02,  5.8012e-02],\n",
              "                        [ 8.4266e-03,  5.4515e-02,  1.0312e-01]],\n",
              "              \n",
              "                       [[-1.1104e-02,  5.2304e-02,  1.8265e-02],\n",
              "                        [ 8.8551e-02, -2.1116e-02,  6.1286e-02],\n",
              "                        [ 9.7437e-02,  4.5545e-02, -6.8156e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 6.8692e-03,  4.5176e-02,  8.8795e-02],\n",
              "                        [ 1.0440e-02, -5.5394e-02,  1.6058e-02],\n",
              "                        [-4.5781e-02, -4.7140e-02,  8.6800e-02]],\n",
              "              \n",
              "                       [[ 1.9268e-02,  9.3240e-02, -6.2060e-02],\n",
              "                        [-8.6601e-02,  3.3677e-02, -2.8212e-02],\n",
              "                        [-4.7088e-02,  6.6620e-02, -4.9379e-02]],\n",
              "              \n",
              "                       [[ 6.2241e-02,  1.2577e-02, -1.6276e-02],\n",
              "                        [-4.3918e-02,  1.9840e-04,  7.1053e-02],\n",
              "                        [ 3.7419e-02,  1.5188e-02, -6.9579e-03]],\n",
              "              \n",
              "                       [[-7.1604e-02, -7.3030e-03,  4.0378e-02],\n",
              "                        [ 1.0052e-01, -5.0038e-02, -7.0088e-02],\n",
              "                        [ 7.2991e-02, -5.3230e-02, -9.5994e-02]],\n",
              "              \n",
              "                       [[-3.7611e-02,  5.2794e-02, -5.2847e-02],\n",
              "                        [-5.0707e-02,  2.1446e-03,  8.4750e-02],\n",
              "                        [-3.1943e-02,  4.6720e-02, -6.8979e-02]],\n",
              "              \n",
              "                       [[ 4.2882e-02, -5.0077e-02, -2.1528e-02],\n",
              "                        [-4.5018e-02,  6.6455e-02,  4.7194e-02],\n",
              "                        [-7.9858e-02,  2.7953e-03, -6.2734e-02]],\n",
              "              \n",
              "                       [[ 9.7149e-02,  5.6929e-02,  8.5864e-02],\n",
              "                        [ 4.9462e-02, -6.0987e-02, -3.0539e-02],\n",
              "                        [ 8.7754e-02,  5.6266e-02,  3.4564e-02]],\n",
              "              \n",
              "                       [[ 4.1991e-02, -2.2435e-03,  2.8675e-05],\n",
              "                        [ 3.2492e-02, -3.7729e-02, -4.5682e-02],\n",
              "                        [ 9.0257e-02, -1.1346e-02,  9.9748e-03]],\n",
              "              \n",
              "                       [[ 6.1020e-02, -1.0186e-03, -4.2329e-02],\n",
              "                        [ 1.8285e-02, -6.6263e-02,  9.9226e-02],\n",
              "                        [-1.3534e-02,  1.0033e-01, -3.6540e-02]],\n",
              "              \n",
              "                       [[-7.4273e-02,  1.0300e-01,  2.2563e-02],\n",
              "                        [-2.7200e-02, -3.9788e-02,  6.0807e-02],\n",
              "                        [ 9.1162e-02,  1.6366e-03, -5.7523e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 6.4782e-02,  4.5474e-02,  5.1363e-02],\n",
              "                        [-8.7829e-02, -6.4763e-02, -1.9011e-02],\n",
              "                        [-3.3078e-02, -5.8121e-02,  6.4261e-02]],\n",
              "              \n",
              "                       [[-2.3073e-02, -6.0062e-02, -8.4697e-02],\n",
              "                        [-2.0622e-02, -1.7192e-02,  5.9721e-02],\n",
              "                        [-4.1685e-02, -1.0446e-01, -2.4540e-02]],\n",
              "              \n",
              "                       [[ 3.7819e-02, -8.1036e-02,  3.5409e-02],\n",
              "                        [-7.0012e-02,  4.4011e-02, -4.6047e-02],\n",
              "                        [ 1.7525e-02,  6.8199e-02, -7.5194e-02]],\n",
              "              \n",
              "                       [[ 6.9899e-02,  2.5913e-02,  8.3270e-02],\n",
              "                        [ 8.0053e-02,  7.3743e-02,  9.0113e-02],\n",
              "                        [-1.2171e-02, -6.4797e-02,  4.7252e-02]],\n",
              "              \n",
              "                       [[-7.9811e-02, -3.8721e-02,  1.1486e-02],\n",
              "                        [ 3.2389e-02, -3.6606e-02,  5.6630e-02],\n",
              "                        [ 1.0371e-01, -2.8487e-02, -5.9079e-02]],\n",
              "              \n",
              "                       [[ 7.2763e-02,  5.1256e-02, -9.0362e-02],\n",
              "                        [ 3.8365e-02,  1.8253e-02,  6.3994e-02],\n",
              "                        [-9.8769e-02,  7.5661e-02, -1.1136e-02]],\n",
              "              \n",
              "                       [[ 3.4942e-02, -8.7591e-02, -4.8204e-02],\n",
              "                        [ 5.7300e-02,  9.1462e-02, -7.6703e-03],\n",
              "                        [ 8.1369e-02, -9.1331e-02, -9.8772e-02]],\n",
              "              \n",
              "                       [[-9.9237e-02, -5.5343e-02,  3.2574e-03],\n",
              "                        [-5.7041e-02, -6.7732e-02, -8.5708e-02],\n",
              "                        [-7.3335e-02,  7.8094e-02,  7.7063e-03]],\n",
              "              \n",
              "                       [[-6.6611e-03, -6.0799e-02, -2.6222e-02],\n",
              "                        [ 2.4344e-02,  9.4315e-02,  7.1333e-02],\n",
              "                        [-5.0970e-02,  1.0037e-01, -9.7442e-02]],\n",
              "              \n",
              "                       [[-3.4719e-02, -4.1413e-02, -1.8169e-02],\n",
              "                        [ 1.7194e-02, -6.9254e-02,  4.9532e-03],\n",
              "                        [ 8.9855e-02,  2.4085e-02, -4.9276e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.1020e-03,  9.0074e-02, -4.1257e-02],\n",
              "                        [ 8.4538e-02, -7.0044e-02, -3.0566e-02],\n",
              "                        [ 6.7803e-02,  7.1097e-02, -3.1199e-02]],\n",
              "              \n",
              "                       [[ 6.2056e-02, -2.2401e-02, -9.8808e-02],\n",
              "                        [-1.2575e-02, -5.1116e-02, -3.6753e-02],\n",
              "                        [-5.8402e-02, -4.5116e-02, -4.6553e-02]],\n",
              "              \n",
              "                       [[-2.2784e-02,  9.8872e-02, -9.3107e-02],\n",
              "                        [ 6.6618e-02,  8.0885e-02,  3.8353e-02],\n",
              "                        [-2.1704e-03, -2.3260e-03,  6.7257e-02]],\n",
              "              \n",
              "                       [[ 5.1304e-02,  3.0558e-02, -5.9395e-02],\n",
              "                        [ 7.0591e-02, -9.8333e-02,  3.5389e-02],\n",
              "                        [-3.2793e-02, -9.1695e-02, -9.0294e-02]],\n",
              "              \n",
              "                       [[ 4.0252e-02, -6.4799e-02, -6.2607e-02],\n",
              "                        [ 7.4449e-02,  5.3460e-02,  3.9401e-02],\n",
              "                        [ 5.6010e-02, -9.0071e-02, -8.7788e-02]],\n",
              "              \n",
              "                       [[ 2.1060e-02, -2.2014e-02, -9.2623e-02],\n",
              "                        [-5.0926e-02,  1.0440e-01, -8.8142e-02],\n",
              "                        [-8.2364e-02, -1.0501e-01,  8.7594e-02]],\n",
              "              \n",
              "                       [[ 9.8499e-02, -1.2695e-02, -5.1993e-02],\n",
              "                        [ 1.6440e-03, -1.0166e-01, -7.1238e-02],\n",
              "                        [ 7.9878e-02, -1.4851e-02,  1.9964e-02]],\n",
              "              \n",
              "                       [[-3.6485e-02, -5.6732e-02,  9.3837e-02],\n",
              "                        [-7.3222e-02,  7.3788e-02, -1.0171e-01],\n",
              "                        [ 1.0012e-01,  4.6407e-02, -2.4369e-02]],\n",
              "              \n",
              "                       [[-3.0386e-02, -5.1500e-02,  3.1976e-04],\n",
              "                        [ 2.7221e-02,  3.1009e-02,  2.9242e-02],\n",
              "                        [-5.8167e-02,  2.6787e-02, -1.1721e-02]],\n",
              "              \n",
              "                       [[ 7.9969e-02, -4.1841e-02,  8.5994e-02],\n",
              "                        [-8.3698e-02,  9.4922e-02,  6.6948e-02],\n",
              "                        [-8.6681e-02, -6.9734e-02,  3.8679e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.0725e-02,  8.4579e-02,  3.6758e-02],\n",
              "                        [-8.0343e-02, -1.4376e-02,  4.8657e-02],\n",
              "                        [ 6.4149e-02, -3.9269e-02, -1.9315e-02]],\n",
              "              \n",
              "                       [[-8.7037e-02, -3.0361e-02,  9.2204e-02],\n",
              "                        [ 5.5762e-02,  3.3592e-02, -8.5078e-02],\n",
              "                        [ 1.1917e-02,  5.5164e-02,  7.9126e-02]],\n",
              "              \n",
              "                       [[ 7.7332e-02,  2.6555e-03,  2.6880e-03],\n",
              "                        [-9.2365e-02,  5.8829e-02,  1.7398e-02],\n",
              "                        [-7.8136e-02,  6.8244e-02,  4.5167e-02]],\n",
              "              \n",
              "                       [[-5.5039e-02, -5.4764e-02,  6.6749e-02],\n",
              "                        [ 7.6627e-02, -8.2626e-02, -7.0648e-02],\n",
              "                        [ 3.1901e-02,  5.7978e-03,  7.1945e-02]],\n",
              "              \n",
              "                       [[-3.3758e-02, -8.5397e-02, -7.5310e-02],\n",
              "                        [-5.7721e-02, -6.1603e-02,  1.7100e-02],\n",
              "                        [ 6.6831e-02, -3.2193e-02, -9.9234e-02]],\n",
              "              \n",
              "                       [[ 7.7533e-02, -2.1321e-02,  3.4614e-02],\n",
              "                        [-9.6930e-02, -4.0460e-03, -6.2058e-02],\n",
              "                        [ 9.3597e-02,  8.6389e-02, -6.9268e-02]],\n",
              "              \n",
              "                       [[-6.8767e-02, -9.6539e-02,  6.5217e-03],\n",
              "                        [ 1.8596e-02, -2.8110e-02,  5.7210e-02],\n",
              "                        [ 5.9537e-02, -2.0876e-02,  9.2241e-02]],\n",
              "              \n",
              "                       [[ 3.5790e-02, -7.4634e-02,  9.4583e-02],\n",
              "                        [ 5.5056e-02, -2.8020e-02, -4.4635e-02],\n",
              "                        [-6.4968e-02, -2.1330e-02,  6.1599e-02]],\n",
              "              \n",
              "                       [[ 6.0422e-02,  9.9530e-02,  7.2869e-02],\n",
              "                        [-9.3146e-02,  1.0366e-01,  5.2490e-02],\n",
              "                        [-1.0396e-01,  4.2636e-02, -7.1482e-03]],\n",
              "              \n",
              "                       [[ 2.0501e-02,  1.7325e-02, -5.0887e-02],\n",
              "                        [-2.4618e-02,  1.0292e-01, -8.0814e-02],\n",
              "                        [ 5.8233e-03, -5.9108e-02,  2.1317e-02]]]])),\n",
              "             ('block1.2.bias',\n",
              "              tensor([-0.0043, -0.0948,  0.0445,  0.0056, -0.0184,  0.0938, -0.0787,  0.0183,\n",
              "                       0.0255,  0.0148])),\n",
              "             ('block2.0.weight',\n",
              "              tensor([[[[ 4.7479e-03, -1.0424e-01, -6.0240e-02],\n",
              "                        [ 8.1240e-02, -1.1017e-03, -4.3536e-02],\n",
              "                        [-6.8311e-02, -2.9480e-02,  4.1605e-02]],\n",
              "              \n",
              "                       [[-1.0669e-02, -8.2010e-03, -8.0772e-02],\n",
              "                        [-8.7766e-02,  5.3388e-02,  4.6909e-02],\n",
              "                        [ 4.4737e-02,  1.1037e-02, -8.0170e-02]],\n",
              "              \n",
              "                       [[-2.9995e-02, -4.2055e-03,  5.0356e-02],\n",
              "                        [ 4.6320e-02,  7.4371e-02, -4.6779e-04],\n",
              "                        [-4.6387e-02,  3.9583e-02, -7.8609e-02]],\n",
              "              \n",
              "                       [[ 1.0372e-01,  4.5563e-02, -6.7368e-02],\n",
              "                        [ 1.1385e-02, -2.5090e-02,  2.7139e-02],\n",
              "                        [-2.8463e-02,  1.7761e-02,  5.6753e-02]],\n",
              "              \n",
              "                       [[-8.5679e-03,  4.7226e-02,  7.4203e-02],\n",
              "                        [ 1.4961e-02, -4.9997e-02,  1.1151e-02],\n",
              "                        [-5.6902e-02,  4.6145e-02,  1.7117e-02]],\n",
              "              \n",
              "                       [[-8.5859e-02,  2.3936e-02,  8.9911e-02],\n",
              "                        [-2.5634e-02, -2.5318e-02,  1.5405e-02],\n",
              "                        [ 9.9135e-02,  6.6700e-02,  3.1031e-03]],\n",
              "              \n",
              "                       [[-7.2469e-02,  6.5792e-02,  9.2655e-02],\n",
              "                        [-7.2332e-02,  1.1635e-02, -7.1391e-02],\n",
              "                        [-5.4459e-03,  4.1974e-02,  6.3933e-02]],\n",
              "              \n",
              "                       [[-9.0582e-02,  3.3310e-02,  4.5951e-02],\n",
              "                        [ 3.0141e-02, -3.8444e-02, -3.1273e-02],\n",
              "                        [ 7.5320e-02,  9.0793e-03,  8.5969e-02]],\n",
              "              \n",
              "                       [[-1.9878e-02,  6.1128e-02, -7.6187e-02],\n",
              "                        [ 8.7352e-02,  5.7664e-02, -6.8973e-02],\n",
              "                        [-2.5737e-02,  3.1038e-02, -2.8952e-05]],\n",
              "              \n",
              "                       [[-6.1116e-02, -5.6161e-02, -2.3771e-02],\n",
              "                        [-5.3944e-02,  2.9919e-02, -6.7522e-02],\n",
              "                        [-8.4962e-02,  5.3489e-02, -2.9226e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.4783e-02, -4.2194e-02,  9.7810e-02],\n",
              "                        [-3.3083e-02,  7.3042e-02, -5.0878e-02],\n",
              "                        [ 1.4096e-03,  8.0704e-02, -2.5850e-02]],\n",
              "              \n",
              "                       [[ 9.8638e-02, -4.0089e-02,  5.2113e-03],\n",
              "                        [ 3.2347e-02, -2.9367e-02,  4.2006e-02],\n",
              "                        [-6.0515e-02,  6.9211e-03,  4.6721e-02]],\n",
              "              \n",
              "                       [[-8.8264e-02, -2.9832e-02, -1.9892e-02],\n",
              "                        [-8.6210e-02, -5.5172e-02,  1.7870e-02],\n",
              "                        [ 8.3896e-02, -1.1718e-02, -8.5138e-02]],\n",
              "              \n",
              "                       [[-2.7351e-02,  3.2412e-02,  6.3773e-02],\n",
              "                        [-6.3305e-02, -9.7097e-03, -6.0037e-02],\n",
              "                        [ 7.3065e-04,  9.1482e-02, -2.4308e-02]],\n",
              "              \n",
              "                       [[-5.4800e-02, -1.0414e-01,  1.0087e-01],\n",
              "                        [ 6.6135e-02,  4.5085e-02,  3.2723e-02],\n",
              "                        [-5.8351e-02,  7.3762e-02, -6.9031e-02]],\n",
              "              \n",
              "                       [[-1.0091e-01, -8.3805e-02, -1.0289e-01],\n",
              "                        [ 4.8304e-02,  7.5374e-02, -9.3834e-02],\n",
              "                        [ 2.6581e-02, -1.9442e-02,  1.6588e-02]],\n",
              "              \n",
              "                       [[-6.1060e-02,  9.9770e-02, -8.4309e-02],\n",
              "                        [-7.4155e-02, -3.8198e-02, -4.3649e-02],\n",
              "                        [-9.7831e-02, -6.9466e-02,  4.5367e-02]],\n",
              "              \n",
              "                       [[-7.3044e-02, -8.0840e-02,  5.1201e-02],\n",
              "                        [-3.8965e-03, -3.4200e-02, -4.4961e-02],\n",
              "                        [-1.4008e-03,  1.0328e-01, -2.2222e-02]],\n",
              "              \n",
              "                       [[ 6.6694e-02, -3.4648e-02,  6.5001e-02],\n",
              "                        [ 1.4981e-02,  6.9388e-02,  8.4967e-02],\n",
              "                        [-7.4273e-02,  8.5785e-02,  7.6990e-02]],\n",
              "              \n",
              "                       [[-8.7171e-02,  5.0265e-02, -8.7946e-02],\n",
              "                        [ 3.2556e-03, -5.5807e-02,  3.7945e-02],\n",
              "                        [-5.1722e-02,  3.3910e-02,  9.0109e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.6404e-02,  5.2553e-02,  8.3826e-02],\n",
              "                        [-2.2540e-02, -2.7727e-02, -1.1679e-02],\n",
              "                        [ 8.4212e-02,  6.6782e-02,  2.5367e-02]],\n",
              "              \n",
              "                       [[-8.5473e-02,  3.6026e-02, -9.2992e-02],\n",
              "                        [ 2.5881e-03, -5.1065e-02, -9.8790e-02],\n",
              "                        [ 7.8554e-02,  4.4000e-02, -7.1864e-02]],\n",
              "              \n",
              "                       [[-5.4247e-02,  8.4568e-02, -9.8077e-02],\n",
              "                        [-9.8013e-02, -3.3140e-02,  8.7777e-02],\n",
              "                        [ 4.6081e-02,  6.8513e-02,  4.6171e-02]],\n",
              "              \n",
              "                       [[-2.9401e-02, -9.9278e-02,  4.3218e-02],\n",
              "                        [ 8.4299e-02,  2.6871e-02, -8.6098e-02],\n",
              "                        [-1.9130e-02,  7.5877e-02, -6.8370e-02]],\n",
              "              \n",
              "                       [[ 1.0422e-02,  4.5778e-02, -2.8718e-02],\n",
              "                        [ 3.5129e-02,  7.7493e-02,  7.9980e-02],\n",
              "                        [ 3.2410e-02,  1.0324e-01, -9.5662e-02]],\n",
              "              \n",
              "                       [[ 7.8024e-02, -7.4353e-02,  2.7729e-02],\n",
              "                        [-9.5503e-02, -4.1060e-02,  8.2667e-02],\n",
              "                        [-8.8792e-02,  6.4289e-02, -5.5961e-02]],\n",
              "              \n",
              "                       [[-3.1480e-02, -6.7597e-02, -4.5730e-02],\n",
              "                        [ 6.7575e-02, -1.4482e-02, -2.5319e-03],\n",
              "                        [ 4.7902e-02,  6.2749e-03,  3.4707e-02]],\n",
              "              \n",
              "                       [[ 5.9461e-02, -2.0479e-02, -2.8018e-02],\n",
              "                        [-6.4168e-02, -4.2731e-02,  7.0166e-02],\n",
              "                        [ 8.9175e-02,  3.6212e-02,  7.7099e-02]],\n",
              "              \n",
              "                       [[-1.1362e-02, -4.6962e-02,  8.6984e-02],\n",
              "                        [ 9.0114e-02, -4.8556e-02, -3.2025e-02],\n",
              "                        [-6.6534e-02, -5.1163e-02,  5.2021e-02]],\n",
              "              \n",
              "                       [[ 5.6882e-02,  6.6344e-02,  1.6858e-02],\n",
              "                        [ 2.7077e-02, -6.4284e-02, -1.8763e-03],\n",
              "                        [-2.7101e-02,  7.1099e-02,  7.8892e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.1218e-02, -6.8876e-02, -1.0432e-01],\n",
              "                        [-6.8841e-02, -4.7812e-02,  1.6569e-02],\n",
              "                        [ 3.6973e-02, -6.8143e-03,  6.7562e-02]],\n",
              "              \n",
              "                       [[ 3.0674e-02,  2.4366e-02,  4.8882e-02],\n",
              "                        [ 7.8550e-02, -8.0711e-02,  6.2874e-02],\n",
              "                        [-5.5607e-02,  1.0222e-01, -3.8578e-02]],\n",
              "              \n",
              "                       [[ 4.6646e-03,  3.9786e-02,  4.9276e-02],\n",
              "                        [ 3.4051e-02,  7.9601e-02,  1.6942e-03],\n",
              "                        [ 1.0446e-01,  5.8358e-02,  1.7542e-02]],\n",
              "              \n",
              "                       [[ 3.0163e-02,  1.0233e-02, -4.8422e-02],\n",
              "                        [ 6.7398e-02,  7.6373e-02, -5.7421e-02],\n",
              "                        [-8.0292e-02,  7.0788e-02, -5.6909e-02]],\n",
              "              \n",
              "                       [[ 5.9324e-02,  4.7509e-02,  5.8741e-02],\n",
              "                        [-2.0662e-02, -1.8956e-02,  9.7406e-02],\n",
              "                        [ 1.7108e-02,  8.3772e-02, -8.7931e-02]],\n",
              "              \n",
              "                       [[ 6.4652e-02, -4.6941e-02,  6.7169e-02],\n",
              "                        [-4.2213e-02,  1.3834e-03,  9.9608e-03],\n",
              "                        [ 8.3953e-02, -9.7881e-03,  7.8798e-02]],\n",
              "              \n",
              "                       [[ 3.0052e-02, -7.8746e-02,  3.8730e-02],\n",
              "                        [-1.3687e-02, -1.1730e-02,  2.2489e-02],\n",
              "                        [-3.1411e-02, -3.8783e-02, -6.0319e-02]],\n",
              "              \n",
              "                       [[ 2.9362e-02,  2.2580e-02,  1.0370e-01],\n",
              "                        [-4.8956e-02,  1.6677e-02, -1.0346e-01],\n",
              "                        [ 3.8413e-02, -9.7167e-02,  9.5293e-02]],\n",
              "              \n",
              "                       [[ 7.8140e-02, -1.0092e-01,  3.9520e-02],\n",
              "                        [-9.9166e-02,  4.3065e-02,  7.1445e-02],\n",
              "                        [ 7.7070e-02,  5.3622e-02, -6.0747e-02]],\n",
              "              \n",
              "                       [[-2.1735e-02,  2.1927e-02, -1.1631e-02],\n",
              "                        [ 7.3091e-02, -5.0472e-02, -1.1603e-02],\n",
              "                        [-4.6150e-04, -3.9604e-03,  7.5171e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 7.8344e-02,  4.4176e-02, -7.6801e-02],\n",
              "                        [-2.5233e-02,  8.0372e-04, -7.5281e-02],\n",
              "                        [-9.0569e-02,  3.7198e-02, -2.6871e-02]],\n",
              "              \n",
              "                       [[-1.0449e-01, -1.5072e-03, -1.0144e-01],\n",
              "                        [-1.7920e-02,  1.0298e-01, -4.4627e-03],\n",
              "                        [-8.3519e-02, -8.9197e-02,  7.0398e-02]],\n",
              "              \n",
              "                       [[-9.9312e-02,  1.7877e-02, -7.1926e-02],\n",
              "                        [-3.7153e-02, -5.6579e-02,  7.2011e-02],\n",
              "                        [ 4.9171e-02, -7.7313e-02,  1.0468e-01]],\n",
              "              \n",
              "                       [[-2.7533e-02,  8.8443e-04,  6.2886e-02],\n",
              "                        [ 1.0681e-02,  3.3989e-03,  6.9315e-02],\n",
              "                        [-1.0515e-01,  6.9450e-02, -7.4577e-02]],\n",
              "              \n",
              "                       [[-1.0147e-01,  1.7553e-02,  1.0149e-01],\n",
              "                        [ 4.1614e-02,  1.0069e-01, -1.5388e-02],\n",
              "                        [-5.0578e-02, -4.0049e-03,  1.3336e-03]],\n",
              "              \n",
              "                       [[ 9.0101e-02, -7.4393e-02, -5.7517e-02],\n",
              "                        [ 6.3397e-02, -7.1399e-02,  1.0095e-01],\n",
              "                        [-3.9320e-02,  4.2751e-02, -4.7053e-02]],\n",
              "              \n",
              "                       [[-1.3060e-02,  7.6379e-02,  4.9418e-02],\n",
              "                        [-6.5331e-02,  4.6473e-02, -4.4233e-02],\n",
              "                        [-8.2435e-02,  6.9311e-02, -4.9606e-02]],\n",
              "              \n",
              "                       [[ 5.4956e-02,  3.0950e-02, -7.7575e-02],\n",
              "                        [-3.7967e-02, -2.1645e-02, -5.5532e-02],\n",
              "                        [-1.8583e-02,  8.5763e-02,  8.3666e-02]],\n",
              "              \n",
              "                       [[-4.2485e-02,  8.1694e-02, -7.1549e-03],\n",
              "                        [ 1.6816e-02, -2.5493e-02, -2.0272e-02],\n",
              "                        [ 1.1562e-02, -7.2298e-02,  8.2588e-02]],\n",
              "              \n",
              "                       [[ 5.5666e-02,  2.5893e-02, -5.8299e-02],\n",
              "                        [-3.2021e-02, -1.0253e-01,  8.2733e-03],\n",
              "                        [-4.5603e-02,  5.6222e-03,  2.2796e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 6.1816e-02,  3.6248e-02, -9.1847e-02],\n",
              "                        [ 8.1633e-02,  4.2757e-02,  3.5357e-02],\n",
              "                        [-1.8516e-02,  4.7660e-03,  6.9464e-02]],\n",
              "              \n",
              "                       [[-9.6299e-02,  9.9353e-02,  1.3547e-02],\n",
              "                        [-1.0357e-01,  7.0544e-03,  9.7343e-02],\n",
              "                        [-3.1748e-02, -2.7553e-02, -1.6208e-02]],\n",
              "              \n",
              "                       [[-1.0362e-01, -4.4676e-02,  5.9921e-02],\n",
              "                        [-6.0029e-02, -8.0325e-02, -6.4448e-02],\n",
              "                        [ 2.4938e-02,  2.8168e-02,  6.3266e-03]],\n",
              "              \n",
              "                       [[-2.5117e-02,  7.9946e-03, -9.1966e-02],\n",
              "                        [-8.4095e-02, -8.5839e-03, -7.2474e-02],\n",
              "                        [-3.6780e-02,  5.5487e-02, -8.3101e-02]],\n",
              "              \n",
              "                       [[-3.6908e-02,  2.6490e-02, -4.3701e-02],\n",
              "                        [ 3.3871e-02, -8.1215e-02,  1.9238e-02],\n",
              "                        [-5.1249e-02, -6.7540e-02,  1.9388e-03]],\n",
              "              \n",
              "                       [[-2.7797e-02, -6.2929e-02, -3.8637e-02],\n",
              "                        [-2.3286e-02,  7.5691e-02,  3.3976e-02],\n",
              "                        [ 2.7952e-02, -3.8031e-02, -5.1312e-02]],\n",
              "              \n",
              "                       [[-4.3897e-02,  3.3233e-03, -1.0460e-01],\n",
              "                        [ 4.7340e-02,  3.3306e-03, -3.5406e-02],\n",
              "                        [-1.2716e-03,  7.2401e-04,  6.2934e-03]],\n",
              "              \n",
              "                       [[ 6.4149e-02,  5.0858e-02,  5.3769e-02],\n",
              "                        [-8.4854e-02,  2.6395e-02,  3.6616e-02],\n",
              "                        [-1.0245e-01, -3.8849e-02, -3.4837e-02]],\n",
              "              \n",
              "                       [[-3.2569e-02, -6.3664e-03, -9.1624e-02],\n",
              "                        [-1.5569e-02,  3.5153e-02,  2.5446e-02],\n",
              "                        [ 7.7628e-02, -8.4002e-02, -7.9790e-02]],\n",
              "              \n",
              "                       [[-2.7726e-02,  1.0252e-01,  8.6878e-02],\n",
              "                        [ 5.7918e-02,  8.7700e-02,  4.4572e-02],\n",
              "                        [ 1.6747e-02, -3.1151e-02, -3.1345e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 5.4760e-02,  5.6815e-02,  7.9866e-02],\n",
              "                        [ 3.1743e-02, -3.1795e-02, -4.2075e-02],\n",
              "                        [ 1.0180e-01,  5.3909e-02,  7.5782e-02]],\n",
              "              \n",
              "                       [[ 9.7257e-02, -4.9750e-02, -8.0664e-03],\n",
              "                        [ 1.3597e-02,  2.1169e-02, -1.4268e-02],\n",
              "                        [-4.8156e-02, -7.8303e-03,  5.1385e-02]],\n",
              "              \n",
              "                       [[ 4.7751e-02, -3.8862e-02,  1.2495e-02],\n",
              "                        [ 8.2543e-02,  1.3528e-02, -5.8618e-02],\n",
              "                        [-5.0704e-02, -5.0122e-02, -1.5379e-02]],\n",
              "              \n",
              "                       [[ 5.5878e-02,  9.2983e-03,  6.4713e-02],\n",
              "                        [ 1.0340e-02, -3.8323e-02, -9.6102e-02],\n",
              "                        [ 3.7450e-03,  8.3319e-02,  9.9146e-02]],\n",
              "              \n",
              "                       [[-2.3849e-02,  6.1157e-02, -1.3212e-02],\n",
              "                        [-2.2938e-02, -3.4056e-02,  2.1799e-02],\n",
              "                        [ 4.3399e-02,  9.2352e-04,  1.9480e-02]],\n",
              "              \n",
              "                       [[-1.0442e-01, -3.0142e-03,  1.0342e-01],\n",
              "                        [ 2.8059e-02,  7.0847e-02,  1.3661e-02],\n",
              "                        [-4.6392e-02, -5.2224e-02, -8.8683e-02]],\n",
              "              \n",
              "                       [[-5.3162e-02,  7.4754e-02,  2.6238e-02],\n",
              "                        [-3.1245e-02,  5.2501e-02,  4.0824e-02],\n",
              "                        [ 8.3222e-02,  6.8776e-02,  7.8494e-02]],\n",
              "              \n",
              "                       [[-1.6486e-03, -4.3100e-02,  4.9643e-02],\n",
              "                        [-1.9053e-02,  7.1305e-02,  1.5271e-02],\n",
              "                        [-7.9310e-02,  6.2839e-02,  7.8574e-02]],\n",
              "              \n",
              "                       [[ 2.2902e-02,  9.7769e-02,  6.0442e-03],\n",
              "                        [-1.0305e-01,  7.8390e-02, -2.6042e-02],\n",
              "                        [-1.9605e-02, -8.4719e-02, -2.0989e-02]],\n",
              "              \n",
              "                       [[ 2.8576e-03,  7.9314e-02, -5.1772e-02],\n",
              "                        [-2.6425e-02, -4.7600e-02, -6.7228e-02],\n",
              "                        [-6.8389e-03,  5.6090e-02,  2.8159e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-6.5363e-02,  1.7234e-02,  7.6805e-02],\n",
              "                        [ 8.4606e-02, -1.7009e-02,  6.7179e-02],\n",
              "                        [ 6.5549e-02,  4.3914e-02,  2.4519e-02]],\n",
              "              \n",
              "                       [[ 6.4971e-02,  2.4148e-02,  4.9682e-02],\n",
              "                        [-6.4907e-02,  2.9600e-02, -5.9277e-02],\n",
              "                        [-3.3030e-02,  3.9131e-02,  8.5724e-02]],\n",
              "              \n",
              "                       [[-1.9890e-02, -1.0256e-01,  5.1474e-02],\n",
              "                        [ 5.8483e-02, -5.5097e-02, -6.8382e-02],\n",
              "                        [ 6.2697e-02,  3.8512e-02, -5.3366e-02]],\n",
              "              \n",
              "                       [[ 1.7709e-02,  1.3939e-02, -4.2648e-02],\n",
              "                        [-4.0570e-03,  7.6897e-02, -9.1250e-02],\n",
              "                        [ 3.5720e-02,  4.6965e-02, -3.0735e-02]],\n",
              "              \n",
              "                       [[-8.5532e-02, -6.3042e-02, -1.1776e-02],\n",
              "                        [-4.9296e-03, -8.4572e-02, -4.8230e-02],\n",
              "                        [-3.0589e-02, -8.8643e-02, -1.1604e-02]],\n",
              "              \n",
              "                       [[ 1.4543e-02, -7.0667e-02,  5.2312e-02],\n",
              "                        [ 2.5023e-02,  3.2386e-02,  4.4162e-02],\n",
              "                        [-6.3122e-02, -7.5625e-03,  8.9756e-02]],\n",
              "              \n",
              "                       [[-7.8271e-02, -7.9712e-02, -7.7396e-02],\n",
              "                        [ 6.3676e-02, -1.0358e-01, -5.0695e-02],\n",
              "                        [ 2.0972e-03, -4.5636e-02, -1.0180e-01]],\n",
              "              \n",
              "                       [[-4.6342e-02, -8.7910e-02, -5.7655e-02],\n",
              "                        [ 2.1013e-02, -1.0181e-01, -3.0301e-02],\n",
              "                        [ 4.3281e-02,  4.5306e-02,  7.5194e-02]],\n",
              "              \n",
              "                       [[ 7.5208e-02,  7.6956e-02,  9.0592e-02],\n",
              "                        [-1.4307e-02, -4.7209e-02, -5.4935e-02],\n",
              "                        [ 7.4749e-02,  5.5049e-02, -6.8511e-02]],\n",
              "              \n",
              "                       [[-1.0294e-01, -3.7663e-02, -6.4177e-02],\n",
              "                        [ 9.4679e-02,  1.2229e-02,  1.7041e-02],\n",
              "                        [ 2.4676e-02, -8.5942e-02, -8.0329e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-3.3607e-03,  2.0024e-02, -5.7062e-02],\n",
              "                        [ 5.9875e-02,  1.3465e-02,  5.2717e-02],\n",
              "                        [ 1.0023e-01,  4.8992e-02,  8.7264e-02]],\n",
              "              \n",
              "                       [[ 5.2357e-02,  8.2721e-02, -1.0182e-01],\n",
              "                        [ 6.8790e-02,  1.3724e-02,  8.2198e-02],\n",
              "                        [ 4.2817e-02,  1.1538e-02, -9.2914e-02]],\n",
              "              \n",
              "                       [[ 7.8932e-02, -5.9952e-02,  7.1930e-02],\n",
              "                        [ 4.5430e-02,  1.4416e-02,  3.9512e-02],\n",
              "                        [-5.0944e-02,  3.7982e-02, -6.7350e-02]],\n",
              "              \n",
              "                       [[ 8.1314e-02,  5.5418e-02,  5.9840e-02],\n",
              "                        [-8.8380e-02,  8.6437e-02,  4.4161e-02],\n",
              "                        [-5.8783e-02, -8.3909e-02, -2.3942e-02]],\n",
              "              \n",
              "                       [[ 2.3287e-03,  9.2788e-02, -4.0861e-02],\n",
              "                        [-4.0090e-02, -1.0025e-01,  1.2191e-02],\n",
              "                        [ 1.9747e-03, -1.2247e-02,  2.8037e-02]],\n",
              "              \n",
              "                       [[ 3.4583e-02,  5.4215e-02, -3.8561e-02],\n",
              "                        [-4.4963e-02, -2.4155e-02,  1.8468e-02],\n",
              "                        [-1.3991e-02, -9.3902e-02, -6.6923e-02]],\n",
              "              \n",
              "                       [[ 8.5298e-02, -7.0059e-03, -4.1993e-02],\n",
              "                        [-2.3737e-02, -8.7238e-02, -6.8914e-02],\n",
              "                        [-5.3070e-02,  4.8295e-02, -5.3638e-02]],\n",
              "              \n",
              "                       [[-8.7283e-03, -9.3259e-02, -7.5982e-02],\n",
              "                        [ 3.6625e-02,  9.7176e-02, -9.2506e-02],\n",
              "                        [ 1.5752e-02, -1.5433e-03,  8.3723e-02]],\n",
              "              \n",
              "                       [[-5.4787e-02, -7.2858e-02,  1.0500e-01],\n",
              "                        [-8.4899e-02,  7.1068e-02, -6.1606e-02],\n",
              "                        [-5.2906e-02, -2.9346e-02,  5.7892e-02]],\n",
              "              \n",
              "                       [[ 6.7139e-02, -6.5382e-02, -7.3051e-02],\n",
              "                        [-7.7687e-02, -2.3705e-02,  3.0407e-02],\n",
              "                        [ 1.0078e-01, -1.9889e-02, -1.3439e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-9.8978e-02, -5.1306e-02,  6.4751e-02],\n",
              "                        [ 1.9677e-02,  8.5745e-02,  4.6899e-02],\n",
              "                        [ 3.9780e-02, -8.4981e-02,  5.0087e-02]],\n",
              "              \n",
              "                       [[ 1.0196e-01, -5.4470e-02,  2.3642e-02],\n",
              "                        [ 6.9765e-02, -2.6287e-02,  7.2697e-02],\n",
              "                        [-8.6798e-02, -4.2879e-02,  7.3903e-02]],\n",
              "              \n",
              "                       [[ 2.4068e-02,  3.4969e-02,  2.6301e-02],\n",
              "                        [-4.1799e-03, -4.1851e-02, -1.7986e-02],\n",
              "                        [-6.3112e-02,  7.4519e-02,  7.4828e-03]],\n",
              "              \n",
              "                       [[-2.7635e-02,  6.3022e-02, -4.2982e-02],\n",
              "                        [ 5.8260e-02,  3.6086e-02, -5.1931e-02],\n",
              "                        [-6.9081e-02, -2.0445e-02, -2.8334e-03]],\n",
              "              \n",
              "                       [[-9.2345e-02, -5.4181e-02,  6.5219e-02],\n",
              "                        [ 4.1682e-02,  4.2080e-02,  2.1312e-02],\n",
              "                        [ 1.5586e-02,  2.6100e-02,  6.9640e-02]],\n",
              "              \n",
              "                       [[ 8.9140e-02,  7.8741e-02, -4.4780e-02],\n",
              "                        [-9.2609e-02,  1.2721e-02, -9.8065e-03],\n",
              "                        [ 6.5279e-02, -3.8132e-02, -6.7926e-02]],\n",
              "              \n",
              "                       [[ 9.8780e-02,  1.2535e-03,  1.9799e-02],\n",
              "                        [ 3.2428e-02, -2.0447e-02, -5.1821e-02],\n",
              "                        [ 6.9834e-03, -7.4742e-02,  7.8004e-02]],\n",
              "              \n",
              "                       [[ 4.1601e-02,  7.8099e-02,  8.5546e-02],\n",
              "                        [ 7.3025e-02,  3.3089e-02, -9.8659e-02],\n",
              "                        [-6.1654e-03, -4.4721e-02, -7.1136e-02]],\n",
              "              \n",
              "                       [[-5.3781e-02, -9.7174e-04,  9.8673e-02],\n",
              "                        [-3.5938e-02,  8.5797e-02, -2.8347e-02],\n",
              "                        [ 1.0009e-01, -5.1028e-02,  8.6627e-03]],\n",
              "              \n",
              "                       [[-5.7731e-02,  1.3248e-02, -4.2622e-02],\n",
              "                        [-4.4381e-02, -7.6893e-02, -6.5543e-02],\n",
              "                        [ 8.9372e-02,  7.2227e-02, -5.7547e-02]]]])),\n",
              "             ('block2.0.bias',\n",
              "              tensor([-0.0298,  0.0060,  0.0389, -0.0469, -0.0161, -0.0646,  0.0778,  0.0313,\n",
              "                       0.0452,  0.0250])),\n",
              "             ('block2.2.weight',\n",
              "              tensor([[[[-0.0077,  0.0733, -0.0702],\n",
              "                        [-0.0517, -0.0572, -0.0528],\n",
              "                        [-0.0857, -0.0843,  0.0353]],\n",
              "              \n",
              "                       [[-0.0509,  0.0569, -0.0446],\n",
              "                        [ 0.0704,  0.0272, -0.0278],\n",
              "                        [ 0.0706, -0.0641, -0.0058]],\n",
              "              \n",
              "                       [[ 0.0391,  0.0269, -0.0937],\n",
              "                        [ 0.0524, -0.0127,  0.0127],\n",
              "                        [ 0.0201,  0.0747, -0.0737]],\n",
              "              \n",
              "                       [[-0.0300, -0.0921,  0.0918],\n",
              "                        [ 0.0212,  0.0289, -0.0623],\n",
              "                        [ 0.0134,  0.0588, -0.0143]],\n",
              "              \n",
              "                       [[ 0.0142, -0.0977,  0.0117],\n",
              "                        [-0.0282,  0.0099,  0.0931],\n",
              "                        [-0.0209,  0.0989, -0.0305]],\n",
              "              \n",
              "                       [[ 0.1034,  0.1032, -0.0722],\n",
              "                        [ 0.0176,  0.0869,  0.0467],\n",
              "                        [ 0.0797, -0.0528,  0.0598]],\n",
              "              \n",
              "                       [[ 0.0272,  0.0711, -0.0259],\n",
              "                        [ 0.0751, -0.0015,  0.1051],\n",
              "                        [-0.0791, -0.0431,  0.0851]],\n",
              "              \n",
              "                       [[-0.0364, -0.0644, -0.0211],\n",
              "                        [ 0.0302,  0.0340, -0.0524],\n",
              "                        [-0.0952,  0.0642, -0.0247]],\n",
              "              \n",
              "                       [[-0.0402,  0.0093,  0.0336],\n",
              "                        [ 0.0371,  0.0552,  0.0971],\n",
              "                        [ 0.0530,  0.0279,  0.1008]],\n",
              "              \n",
              "                       [[-0.0444,  0.0004, -0.0984],\n",
              "                        [ 0.0153, -0.0908, -0.0790],\n",
              "                        [ 0.0329, -0.0412,  0.0594]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0898,  0.0923,  0.0509],\n",
              "                        [ 0.0839,  0.0862,  0.0554],\n",
              "                        [ 0.0730, -0.0226,  0.0891]],\n",
              "              \n",
              "                       [[-0.0961,  0.0144,  0.0546],\n",
              "                        [-0.0899, -0.0957, -0.0743],\n",
              "                        [ 0.0245,  0.0458,  0.0586]],\n",
              "              \n",
              "                       [[-0.0751, -0.0592,  0.0117],\n",
              "                        [-0.1010,  0.0965, -0.0927],\n",
              "                        [-0.0986,  0.0879, -0.0291]],\n",
              "              \n",
              "                       [[ 0.0853,  0.0554, -0.0193],\n",
              "                        [-0.0460, -0.0734,  0.0100],\n",
              "                        [ 0.0957, -0.0398, -0.0674]],\n",
              "              \n",
              "                       [[ 0.0955, -0.0314, -0.0749],\n",
              "                        [ 0.0151,  0.0824,  0.0479],\n",
              "                        [-0.0382,  0.0050,  0.0042]],\n",
              "              \n",
              "                       [[ 0.0527,  0.0441,  0.0574],\n",
              "                        [ 0.0543,  0.0304, -0.0104],\n",
              "                        [ 0.0956,  0.0048, -0.0780]],\n",
              "              \n",
              "                       [[ 0.0180, -0.0168, -0.0452],\n",
              "                        [ 0.0868,  0.0046, -0.0422],\n",
              "                        [ 0.0192,  0.0952, -0.0938]],\n",
              "              \n",
              "                       [[-0.0052,  0.0030, -0.0902],\n",
              "                        [-0.0079, -0.0133, -0.0897],\n",
              "                        [-0.0921,  0.0894,  0.0516]],\n",
              "              \n",
              "                       [[ 0.0870,  0.0103, -0.1031],\n",
              "                        [ 0.0045,  0.0129, -0.0062],\n",
              "                        [ 0.0024,  0.0064, -0.0290]],\n",
              "              \n",
              "                       [[-0.0042, -0.0564, -0.0364],\n",
              "                        [-0.0633, -0.0668, -0.0937],\n",
              "                        [ 0.0560,  0.0949,  0.0854]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0936,  0.0322,  0.0601],\n",
              "                        [-0.0320, -0.0874,  0.0578],\n",
              "                        [-0.0542, -0.0086, -0.0359]],\n",
              "              \n",
              "                       [[ 0.0037,  0.0445,  0.0031],\n",
              "                        [-0.0638,  0.0593,  0.0307],\n",
              "                        [ 0.0257,  0.0426,  0.0636]],\n",
              "              \n",
              "                       [[ 0.0687,  0.0304, -0.0438],\n",
              "                        [-0.0498,  0.0370,  0.0292],\n",
              "                        [-0.0365, -0.0696,  0.0419]],\n",
              "              \n",
              "                       [[-0.0500,  0.0853,  0.0358],\n",
              "                        [-0.0271,  0.1038, -0.0264],\n",
              "                        [-0.0807,  0.0665, -0.0460]],\n",
              "              \n",
              "                       [[-0.0382,  0.0223, -0.0357],\n",
              "                        [ 0.0067, -0.0048,  0.0116],\n",
              "                        [ 0.0093,  0.0054, -0.0841]],\n",
              "              \n",
              "                       [[-0.0403,  0.0183,  0.0062],\n",
              "                        [ 0.0288,  0.0459, -0.0454],\n",
              "                        [-0.0958, -0.0417,  0.0106]],\n",
              "              \n",
              "                       [[ 0.0048, -0.0849,  0.0602],\n",
              "                        [ 0.0548,  0.0355,  0.0372],\n",
              "                        [-0.0536, -0.0010, -0.0691]],\n",
              "              \n",
              "                       [[ 0.0549, -0.0416,  0.0192],\n",
              "                        [ 0.0143, -0.0282, -0.0924],\n",
              "                        [-0.0280,  0.0894, -0.0610]],\n",
              "              \n",
              "                       [[-0.0986, -0.0301, -0.0758],\n",
              "                        [-0.0727,  0.0485, -0.0968],\n",
              "                        [ 0.0537, -0.0389, -0.0873]],\n",
              "              \n",
              "                       [[-0.0090,  0.0143,  0.0268],\n",
              "                        [ 0.0885, -0.0109,  0.0346],\n",
              "                        [-0.0193, -0.0026,  0.0128]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0587,  0.0464, -0.0516],\n",
              "                        [-0.0217,  0.0270,  0.0742],\n",
              "                        [-0.0972,  0.0625, -0.0509]],\n",
              "              \n",
              "                       [[ 0.0867,  0.0688,  0.0130],\n",
              "                        [-0.0714, -0.0585,  0.0230],\n",
              "                        [ 0.0812, -0.0316, -0.0009]],\n",
              "              \n",
              "                       [[-0.0029, -0.0186, -0.0453],\n",
              "                        [ 0.0419, -0.0251, -0.0138],\n",
              "                        [-0.0887,  0.0866, -0.0559]],\n",
              "              \n",
              "                       [[ 0.1051, -0.0578, -0.0063],\n",
              "                        [ 0.0289,  0.0333, -0.1045],\n",
              "                        [ 0.0924, -0.0068, -0.0147]],\n",
              "              \n",
              "                       [[-0.0204, -0.0493, -0.0786],\n",
              "                        [-0.0900,  0.1052, -0.0636],\n",
              "                        [ 0.0971,  0.0771,  0.0602]],\n",
              "              \n",
              "                       [[ 0.0515,  0.0058, -0.0910],\n",
              "                        [-0.0703,  0.0114,  0.0575],\n",
              "                        [ 0.0201,  0.0269,  0.1030]],\n",
              "              \n",
              "                       [[ 0.0597,  0.0296,  0.0672],\n",
              "                        [-0.0693, -0.0987, -0.0967],\n",
              "                        [-0.0109, -0.0449,  0.0093]],\n",
              "              \n",
              "                       [[-0.1018,  0.0426,  0.0098],\n",
              "                        [ 0.0926,  0.0567, -0.0872],\n",
              "                        [ 0.0854,  0.0694,  0.0358]],\n",
              "              \n",
              "                       [[-0.0319, -0.0272, -0.0262],\n",
              "                        [-0.0055, -0.0200,  0.0045],\n",
              "                        [ 0.0466,  0.0646,  0.0173]],\n",
              "              \n",
              "                       [[ 0.0757,  0.1041,  0.0592],\n",
              "                        [ 0.1043, -0.0075, -0.0563],\n",
              "                        [-0.0035,  0.0666,  0.0882]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0554,  0.0722,  0.0601],\n",
              "                        [-0.0848, -0.0007,  0.0402],\n",
              "                        [ 0.0921,  0.0975, -0.0757]],\n",
              "              \n",
              "                       [[-0.0354, -0.0644,  0.0369],\n",
              "                        [ 0.0833,  0.0356,  0.0445],\n",
              "                        [ 0.0479, -0.0841,  0.0812]],\n",
              "              \n",
              "                       [[-0.0486,  0.1045, -0.0827],\n",
              "                        [-0.0951, -0.0605, -0.0585],\n",
              "                        [ 0.0530, -0.0391, -0.0100]],\n",
              "              \n",
              "                       [[ 0.0809, -0.0874,  0.0250],\n",
              "                        [ 0.0572,  0.0512,  0.0622],\n",
              "                        [ 0.0915, -0.0405, -0.0690]],\n",
              "              \n",
              "                       [[-0.0464, -0.0312, -0.0892],\n",
              "                        [ 0.0832, -0.0466, -0.0978],\n",
              "                        [-0.0545, -0.0001,  0.0526]],\n",
              "              \n",
              "                       [[-0.0906,  0.0079, -0.0064],\n",
              "                        [ 0.0614,  0.0293, -0.0774],\n",
              "                        [ 0.0744,  0.0311, -0.0338]],\n",
              "              \n",
              "                       [[ 0.0910,  0.0385,  0.0506],\n",
              "                        [ 0.0346, -0.0387,  0.0397],\n",
              "                        [ 0.0720, -0.0724, -0.0492]],\n",
              "              \n",
              "                       [[ 0.0751,  0.0458, -0.0175],\n",
              "                        [ 0.0136,  0.0312, -0.0250],\n",
              "                        [-0.0387,  0.0920, -0.0739]],\n",
              "              \n",
              "                       [[-0.1003, -0.0581,  0.0371],\n",
              "                        [-0.0364, -0.0609,  0.0176],\n",
              "                        [ 0.0017, -0.1052, -0.0717]],\n",
              "              \n",
              "                       [[-0.0807, -0.1005, -0.0524],\n",
              "                        [ 0.0152,  0.0203,  0.0582],\n",
              "                        [-0.0547,  0.0309, -0.0494]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0729, -0.0733,  0.0235],\n",
              "                        [-0.0619,  0.0179, -0.0192],\n",
              "                        [-0.0889,  0.0057,  0.0433]],\n",
              "              \n",
              "                       [[-0.0733, -0.0099,  0.1036],\n",
              "                        [-0.0057,  0.0988,  0.0759],\n",
              "                        [ 0.1007, -0.0371,  0.0391]],\n",
              "              \n",
              "                       [[-0.0757,  0.0420, -0.0113],\n",
              "                        [-0.1043, -0.0241, -0.1015],\n",
              "                        [ 0.0224, -0.0892, -0.0710]],\n",
              "              \n",
              "                       [[ 0.0185,  0.0828, -0.0636],\n",
              "                        [-0.0302, -0.0319,  0.0300],\n",
              "                        [ 0.0611, -0.0170,  0.0229]],\n",
              "              \n",
              "                       [[ 0.0672, -0.0104, -0.0188],\n",
              "                        [ 0.0774,  0.0088,  0.0939],\n",
              "                        [-0.0870,  0.0656,  0.0500]],\n",
              "              \n",
              "                       [[-0.0486, -0.0179, -0.0809],\n",
              "                        [-0.0699,  0.0348, -0.0162],\n",
              "                        [-0.0927,  0.0621, -0.0903]],\n",
              "              \n",
              "                       [[ 0.0064, -0.0010,  0.0117],\n",
              "                        [-0.0714,  0.0506, -0.0522],\n",
              "                        [-0.0869,  0.0185, -0.0410]],\n",
              "              \n",
              "                       [[ 0.0875,  0.0006,  0.0415],\n",
              "                        [-0.0440,  0.0007, -0.0662],\n",
              "                        [-0.0152, -0.0316, -0.0659]],\n",
              "              \n",
              "                       [[ 0.0514,  0.1002, -0.0297],\n",
              "                        [ 0.0294,  0.0521,  0.0505],\n",
              "                        [ 0.0617,  0.0738, -0.0681]],\n",
              "              \n",
              "                       [[-0.0348,  0.0281,  0.0052],\n",
              "                        [ 0.0639, -0.0679, -0.0354],\n",
              "                        [ 0.0574,  0.0327,  0.0460]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0316, -0.0079,  0.0324],\n",
              "                        [-0.0840,  0.0357, -0.0250],\n",
              "                        [ 0.0451, -0.1045, -0.0743]],\n",
              "              \n",
              "                       [[ 0.0889,  0.0274, -0.0021],\n",
              "                        [ 0.0303, -0.0612, -0.0562],\n",
              "                        [ 0.0120,  0.0969,  0.0418]],\n",
              "              \n",
              "                       [[ 0.0847, -0.0610,  0.0973],\n",
              "                        [ 0.0415, -0.0802,  0.0038],\n",
              "                        [-0.0501, -0.0211,  0.0416]],\n",
              "              \n",
              "                       [[ 0.0195, -0.0065, -0.0113],\n",
              "                        [-0.0395, -0.1000,  0.0739],\n",
              "                        [-0.0854, -0.0439, -0.0419]],\n",
              "              \n",
              "                       [[ 0.0321,  0.0042,  0.0152],\n",
              "                        [ 0.0859, -0.0367,  0.0420],\n",
              "                        [-0.0078,  0.0062,  0.1040]],\n",
              "              \n",
              "                       [[ 0.0509,  0.0373,  0.0100],\n",
              "                        [ 0.0203, -0.0722, -0.0913],\n",
              "                        [-0.0977, -0.0690, -0.0760]],\n",
              "              \n",
              "                       [[ 0.0183,  0.0705, -0.0613],\n",
              "                        [ 0.0573, -0.0965,  0.0145],\n",
              "                        [ 0.0138,  0.0787,  0.0198]],\n",
              "              \n",
              "                       [[-0.0378, -0.0521, -0.0311],\n",
              "                        [-0.0285, -0.0980, -0.0755],\n",
              "                        [-0.0607, -0.0500,  0.1033]],\n",
              "              \n",
              "                       [[ 0.0923,  0.0030, -0.0852],\n",
              "                        [ 0.0377,  0.0747, -0.0021],\n",
              "                        [ 0.0975, -0.1013,  0.0132]],\n",
              "              \n",
              "                       [[ 0.0428,  0.0403,  0.0079],\n",
              "                        [ 0.0717, -0.0490,  0.1022],\n",
              "                        [ 0.0930, -0.0980, -0.0373]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0603,  0.0805,  0.0015],\n",
              "                        [-0.0228, -0.0383,  0.0626],\n",
              "                        [ 0.0741, -0.0380, -0.0441]],\n",
              "              \n",
              "                       [[ 0.0246, -0.0760, -0.0156],\n",
              "                        [-0.0446, -0.0334,  0.0475],\n",
              "                        [ 0.1042, -0.0020, -0.0696]],\n",
              "              \n",
              "                       [[ 0.0134,  0.0056,  0.0499],\n",
              "                        [-0.0338, -0.0741, -0.0890],\n",
              "                        [ 0.0759, -0.0555, -0.0157]],\n",
              "              \n",
              "                       [[-0.0869, -0.0979, -0.0547],\n",
              "                        [ 0.0695, -0.0102, -0.0949],\n",
              "                        [-0.0300,  0.0832,  0.0960]],\n",
              "              \n",
              "                       [[-0.0977,  0.0736,  0.0089],\n",
              "                        [-0.1021, -0.0882, -0.0030],\n",
              "                        [ 0.1017, -0.0685,  0.0876]],\n",
              "              \n",
              "                       [[ 0.0065, -0.0936, -0.0206],\n",
              "                        [ 0.0577,  0.0421,  0.0067],\n",
              "                        [ 0.0220, -0.0860, -0.0757]],\n",
              "              \n",
              "                       [[-0.0541, -0.0696, -0.0564],\n",
              "                        [ 0.0910, -0.0425,  0.0688],\n",
              "                        [ 0.0421,  0.0345,  0.0121]],\n",
              "              \n",
              "                       [[ 0.0458, -0.0981,  0.0691],\n",
              "                        [ 0.0334, -0.0953, -0.0968],\n",
              "                        [-0.0828,  0.0594, -0.0566]],\n",
              "              \n",
              "                       [[ 0.0719, -0.0670,  0.0017],\n",
              "                        [ 0.0593, -0.1031, -0.0609],\n",
              "                        [ 0.0429,  0.0302,  0.0703]],\n",
              "              \n",
              "                       [[-0.0775,  0.0441,  0.0685],\n",
              "                        [-0.0790,  0.0173,  0.0208],\n",
              "                        [-0.0964,  0.0903, -0.0413]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0393, -0.0032, -0.0009],\n",
              "                        [ 0.0345, -0.0186, -0.0134],\n",
              "                        [-0.0913, -0.0800, -0.0013]],\n",
              "              \n",
              "                       [[ 0.0212, -0.0750,  0.0027],\n",
              "                        [-0.0978,  0.1037, -0.0138],\n",
              "                        [-0.0596, -0.0430, -0.0899]],\n",
              "              \n",
              "                       [[ 0.0834, -0.0556,  0.0078],\n",
              "                        [ 0.0536,  0.0300, -0.0408],\n",
              "                        [-0.0574, -0.0433,  0.0686]],\n",
              "              \n",
              "                       [[-0.0892, -0.0999, -0.0167],\n",
              "                        [-0.0751, -0.0959,  0.0818],\n",
              "                        [ 0.0875,  0.0012,  0.0739]],\n",
              "              \n",
              "                       [[ 0.0461,  0.0333, -0.0544],\n",
              "                        [ 0.0192,  0.0899, -0.0252],\n",
              "                        [-0.0432, -0.0605, -0.0029]],\n",
              "              \n",
              "                       [[ 0.0990, -0.0896, -0.0983],\n",
              "                        [-0.0393, -0.0833,  0.0823],\n",
              "                        [-0.0892, -0.0117, -0.1022]],\n",
              "              \n",
              "                       [[-0.0972,  0.1008, -0.0792],\n",
              "                        [-0.0616, -0.0175,  0.0768],\n",
              "                        [ 0.0194,  0.0265,  0.0245]],\n",
              "              \n",
              "                       [[-0.0637, -0.0139,  0.0926],\n",
              "                        [-0.0368, -0.0454, -0.0936],\n",
              "                        [-0.0360,  0.0939,  0.0709]],\n",
              "              \n",
              "                       [[ 0.0248,  0.0470,  0.0110],\n",
              "                        [-0.0432, -0.0729, -0.0676],\n",
              "                        [ 0.0620, -0.0169,  0.1007]],\n",
              "              \n",
              "                       [[ 0.0642,  0.0009, -0.0091],\n",
              "                        [-0.0591, -0.0126, -0.0201],\n",
              "                        [-0.0009,  0.0379,  0.1031]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0298, -0.0009,  0.0830],\n",
              "                        [ 0.1049, -0.0339, -0.0055],\n",
              "                        [ 0.0778,  0.0045, -0.0144]],\n",
              "              \n",
              "                       [[-0.0966,  0.0932,  0.0955],\n",
              "                        [-0.0246,  0.0981,  0.0572],\n",
              "                        [ 0.1017,  0.0967, -0.0754]],\n",
              "              \n",
              "                       [[ 0.0602, -0.0478,  0.0073],\n",
              "                        [-0.0455, -0.0685, -0.0504],\n",
              "                        [-0.0432,  0.0527,  0.0580]],\n",
              "              \n",
              "                       [[ 0.0873,  0.0595,  0.0133],\n",
              "                        [-0.0649,  0.0386,  0.0864],\n",
              "                        [-0.1038,  0.0076,  0.1004]],\n",
              "              \n",
              "                       [[ 0.0814, -0.0635,  0.0074],\n",
              "                        [ 0.0904,  0.0700,  0.0520],\n",
              "                        [-0.0741, -0.0320,  0.0282]],\n",
              "              \n",
              "                       [[ 0.0765, -0.0832, -0.0448],\n",
              "                        [ 0.0943, -0.0826,  0.0497],\n",
              "                        [ 0.0331, -0.0624, -0.0601]],\n",
              "              \n",
              "                       [[ 0.0171,  0.0589, -0.0901],\n",
              "                        [ 0.0850,  0.0429,  0.0632],\n",
              "                        [-0.0027,  0.0378, -0.0319]],\n",
              "              \n",
              "                       [[ 0.0310,  0.0726,  0.0719],\n",
              "                        [ 0.0194, -0.0257,  0.0351],\n",
              "                        [-0.0677,  0.0123,  0.0142]],\n",
              "              \n",
              "                       [[-0.0584,  0.0927,  0.0403],\n",
              "                        [ 0.0330, -0.0974, -0.0636],\n",
              "                        [-0.0850, -0.0188,  0.0659]],\n",
              "              \n",
              "                       [[ 0.0521, -0.0461, -0.0292],\n",
              "                        [ 0.1052,  0.0188, -0.0565],\n",
              "                        [ 0.0610,  0.0771, -0.0510]]]])),\n",
              "             ('block2.2.bias',\n",
              "              tensor([-0.0241, -0.0532,  0.0881,  0.0708,  0.0099,  0.0826, -0.0542,  0.0273,\n",
              "                      -0.0602, -0.0710])),\n",
              "             ('classifier.1.weight',\n",
              "              tensor([[ 0.0012,  0.0003, -0.0018,  ..., -0.0033,  0.0041,  0.0016],\n",
              "                      [-0.0039, -0.0015, -0.0002,  ...,  0.0041,  0.0038, -0.0035]])),\n",
              "             ('classifier.1.bias', tensor([ 0.0012, -0.0020]))])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model = AdClassification(3, 10, len(train_data.classes))\n",
        "\n",
        "model.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8JjzKXab26U",
        "outputId": "46bbd128-9e1b-45b3-8503-65f326c6abe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x00000262CAB60AC0>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9gCWGHnqb26U"
      },
      "outputs": [],
      "source": [
        "optimizer  = torch.optim.SGD(params = model.parameters(), lr = 0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-vRJYJovb26U"
      },
      "outputs": [],
      "source": [
        "def train_step(model: nn.Module,\n",
        "               train_loader : torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer):\n",
        "    model.train()\n",
        "\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "\n",
        "        pred_y = model(X)\n",
        "        loss = loss_fn(pred_y, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred_class = torch.argmax(torch.softmax(pred_y, dim = 1), dim = 1)\n",
        "        train_acc += (pred_class == y).sum().item()/len(pred_y)\n",
        "\n",
        "    train_loss = train_loss/len(train_loader)\n",
        "    train_acc = train_acc/len(train_loader)\n",
        "\n",
        "    return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YWZcfCcOb26V"
      },
      "outputs": [],
      "source": [
        "def test_step(\n",
        "        model: nn.Module,\n",
        "        test_loader : torch.utils.data.DataLoader,\n",
        "        loss_fn : torch.nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "\n",
        "        for batch, (X,y) in enumerate(test_loader):\n",
        "\n",
        "            pred_y = model(X)\n",
        "            loss = loss_fn(pred_y, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            pred_class = torch.argmax(torch.softmax(pred_y, dim =1), dim =1)\n",
        "            test_acc += (pred_class == y).sum().item()/len(pred_y)\n",
        "\n",
        "        test_loss = test_loss/len(test_loader)\n",
        "        test_acc = test_acc/len(test_loader)\n",
        "\n",
        "        return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "44yfw-rsb26V"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Take in various parameters required for training and test steps\n",
        "def train(model: torch.nn.Module,\n",
        "          train_loader: torch.utils.data.DataLoader,\n",
        "          test_loader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 250):\n",
        "\n",
        "    # 2. Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # 3. Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           train_loader=train_loader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer)\n",
        "\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "            test_loader=test_loader,\n",
        "            loss_fn=loss_fn)\n",
        "\n",
        "        # 4. Print out what's happening\n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"train_acc: {train_acc:.4f} | \"\n",
        "            f\"test_loss: {test_loss:.4f} | \"\n",
        "            f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # 5. Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    # 6. Return the filled results at the end of the epochs\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0eb078fb6a5b400eaef2df17ad3a98a9",
            "cbe9238a0f3f4008811cb1a9701acaf6",
            "5002e9e0a6564118b71d593472797254",
            "390d2e6695fb4bdf9061e8da785cbe6e",
            "fd4b53be5fbe4021b1a32c18ef951427",
            "5cfac7a3b2ef4d75a2f682a7d1a6b1a1",
            "729c347bc0404f49bb14569eaba16401",
            "1424a6d79f224ccc973e1e975681f889",
            "5a1ce453518c407f807b1febbb9b1f05",
            "aab6033643994b25959c23fe9c76b206",
            "7f0902bf77264c9a8807b804c00a3860"
          ]
        },
        "id": "7GPuLi3Wb26V",
        "outputId": "8266fe34-558f-4dc9-bab9-ffafb22e275d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0eb078fb6a5b400eaef2df17ad3a98a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.5744 | train_acc: 0.7216 | test_loss: 0.8754 | test_acc: 0.5217\n",
            "Epoch: 2 | train_loss: 0.5515 | train_acc: 0.7010 | test_loss: 0.8005 | test_acc: 0.5217\n",
            "Epoch: 3 | train_loss: 0.5609 | train_acc: 0.6907 | test_loss: 0.7413 | test_acc: 0.5217\n",
            "Epoch: 4 | train_loss: 0.5693 | train_acc: 0.7010 | test_loss: 0.7700 | test_acc: 0.5652\n",
            "Epoch: 5 | train_loss: 0.5845 | train_acc: 0.7113 | test_loss: 0.7060 | test_acc: 0.6087\n",
            "Epoch: 6 | train_loss: 0.5792 | train_acc: 0.6186 | test_loss: 0.6993 | test_acc: 0.4348\n",
            "Epoch: 7 | train_loss: 0.5431 | train_acc: 0.7423 | test_loss: 0.9925 | test_acc: 0.4783\n",
            "Epoch: 8 | train_loss: 0.5762 | train_acc: 0.7526 | test_loss: 0.7567 | test_acc: 0.5652\n",
            "Epoch: 9 | train_loss: 0.5441 | train_acc: 0.7629 | test_loss: 0.8902 | test_acc: 0.5217\n",
            "Epoch: 10 | train_loss: 0.5415 | train_acc: 0.7216 | test_loss: 0.7934 | test_acc: 0.6087\n",
            "Epoch: 11 | train_loss: 0.5697 | train_acc: 0.7113 | test_loss: 0.9897 | test_acc: 0.6087\n",
            "Epoch: 12 | train_loss: 0.5862 | train_acc: 0.6804 | test_loss: 0.8142 | test_acc: 0.5652\n",
            "Epoch: 13 | train_loss: 0.5440 | train_acc: 0.7320 | test_loss: 0.7524 | test_acc: 0.7391\n",
            "Epoch: 14 | train_loss: 0.5656 | train_acc: 0.7423 | test_loss: 0.8190 | test_acc: 0.5217\n",
            "Epoch: 15 | train_loss: 0.5338 | train_acc: 0.7320 | test_loss: 0.9079 | test_acc: 0.4783\n",
            "Epoch: 16 | train_loss: 0.5121 | train_acc: 0.7113 | test_loss: 0.9885 | test_acc: 0.5217\n",
            "Epoch: 17 | train_loss: 0.5268 | train_acc: 0.7423 | test_loss: 0.9446 | test_acc: 0.4783\n",
            "Epoch: 18 | train_loss: 0.5471 | train_acc: 0.7320 | test_loss: 0.8488 | test_acc: 0.4348\n",
            "Epoch: 19 | train_loss: 0.5547 | train_acc: 0.7423 | test_loss: 0.7468 | test_acc: 0.5652\n",
            "Epoch: 20 | train_loss: 0.5370 | train_acc: 0.7629 | test_loss: 0.8138 | test_acc: 0.4783\n",
            "Epoch: 21 | train_loss: 0.4983 | train_acc: 0.7423 | test_loss: 0.9480 | test_acc: 0.4783\n",
            "Epoch: 22 | train_loss: 0.5460 | train_acc: 0.7113 | test_loss: 0.8892 | test_acc: 0.6087\n",
            "Epoch: 23 | train_loss: 0.5321 | train_acc: 0.7423 | test_loss: 0.8725 | test_acc: 0.5217\n",
            "Epoch: 24 | train_loss: 0.5478 | train_acc: 0.7320 | test_loss: 0.8096 | test_acc: 0.6087\n",
            "Epoch: 25 | train_loss: 0.5295 | train_acc: 0.7629 | test_loss: 0.8311 | test_acc: 0.5217\n",
            "Epoch: 26 | train_loss: 0.5110 | train_acc: 0.7629 | test_loss: 0.7994 | test_acc: 0.5652\n",
            "Epoch: 27 | train_loss: 0.5167 | train_acc: 0.7938 | test_loss: 0.8781 | test_acc: 0.5217\n",
            "Epoch: 28 | train_loss: 0.5442 | train_acc: 0.7113 | test_loss: 0.8417 | test_acc: 0.4348\n",
            "Epoch: 29 | train_loss: 0.5321 | train_acc: 0.7526 | test_loss: 0.8238 | test_acc: 0.5217\n",
            "Epoch: 30 | train_loss: 0.4806 | train_acc: 0.7629 | test_loss: 0.8809 | test_acc: 0.5217\n",
            "Epoch: 31 | train_loss: 0.5181 | train_acc: 0.7423 | test_loss: 0.6712 | test_acc: 0.5217\n",
            "Epoch: 32 | train_loss: 0.4736 | train_acc: 0.7216 | test_loss: 0.9999 | test_acc: 0.6087\n",
            "Epoch: 33 | train_loss: 0.5345 | train_acc: 0.7526 | test_loss: 0.9328 | test_acc: 0.5652\n",
            "Epoch: 34 | train_loss: 0.4798 | train_acc: 0.7526 | test_loss: 0.8968 | test_acc: 0.5217\n",
            "Epoch: 35 | train_loss: 0.4862 | train_acc: 0.7423 | test_loss: 0.8648 | test_acc: 0.6087\n",
            "Epoch: 36 | train_loss: 0.5206 | train_acc: 0.7320 | test_loss: 0.9004 | test_acc: 0.6087\n",
            "Epoch: 37 | train_loss: 0.4995 | train_acc: 0.7629 | test_loss: 0.8470 | test_acc: 0.5217\n",
            "Epoch: 38 | train_loss: 0.4938 | train_acc: 0.7526 | test_loss: 1.0118 | test_acc: 0.4348\n",
            "Epoch: 39 | train_loss: 0.5063 | train_acc: 0.7113 | test_loss: 0.7967 | test_acc: 0.5652\n",
            "Epoch: 40 | train_loss: 0.5246 | train_acc: 0.7526 | test_loss: 0.6909 | test_acc: 0.5652\n",
            "Epoch: 41 | train_loss: 0.4619 | train_acc: 0.7835 | test_loss: 1.1258 | test_acc: 0.4348\n",
            "Epoch: 42 | train_loss: 0.4770 | train_acc: 0.7320 | test_loss: 0.9011 | test_acc: 0.4783\n",
            "Epoch: 43 | train_loss: 0.5235 | train_acc: 0.7113 | test_loss: 0.9424 | test_acc: 0.5217\n",
            "Epoch: 44 | train_loss: 0.5019 | train_acc: 0.7732 | test_loss: 0.9489 | test_acc: 0.5652\n",
            "Epoch: 45 | train_loss: 0.4839 | train_acc: 0.7526 | test_loss: 0.9868 | test_acc: 0.4783\n",
            "Epoch: 46 | train_loss: 0.4767 | train_acc: 0.7835 | test_loss: 0.8182 | test_acc: 0.4348\n",
            "Epoch: 47 | train_loss: 0.4470 | train_acc: 0.7629 | test_loss: 0.9883 | test_acc: 0.5652\n",
            "Epoch: 48 | train_loss: 0.4889 | train_acc: 0.7423 | test_loss: 0.7784 | test_acc: 0.4783\n",
            "Epoch: 49 | train_loss: 0.4631 | train_acc: 0.8041 | test_loss: 0.9386 | test_acc: 0.4783\n",
            "Epoch: 50 | train_loss: 0.5043 | train_acc: 0.7629 | test_loss: 0.9511 | test_acc: 0.4783\n",
            "Epoch: 51 | train_loss: 0.4733 | train_acc: 0.7938 | test_loss: 0.9152 | test_acc: 0.4783\n",
            "Epoch: 52 | train_loss: 0.4642 | train_acc: 0.7938 | test_loss: 0.7485 | test_acc: 0.6087\n",
            "Epoch: 53 | train_loss: 0.4563 | train_acc: 0.7835 | test_loss: 1.2035 | test_acc: 0.6087\n",
            "Epoch: 54 | train_loss: 0.4343 | train_acc: 0.8144 | test_loss: 0.8541 | test_acc: 0.5652\n",
            "Epoch: 55 | train_loss: 0.4858 | train_acc: 0.7732 | test_loss: 0.9530 | test_acc: 0.6087\n",
            "Epoch: 56 | train_loss: 0.4780 | train_acc: 0.7732 | test_loss: 0.9338 | test_acc: 0.5217\n",
            "Epoch: 57 | train_loss: 0.4789 | train_acc: 0.7629 | test_loss: 0.7545 | test_acc: 0.6522\n",
            "Epoch: 58 | train_loss: 0.4784 | train_acc: 0.7732 | test_loss: 1.0127 | test_acc: 0.4783\n",
            "Epoch: 59 | train_loss: 0.4288 | train_acc: 0.8041 | test_loss: 0.8864 | test_acc: 0.5217\n",
            "Epoch: 60 | train_loss: 0.4173 | train_acc: 0.7835 | test_loss: 0.9613 | test_acc: 0.6957\n",
            "Epoch: 61 | train_loss: 0.4118 | train_acc: 0.8351 | test_loss: 0.9689 | test_acc: 0.4348\n",
            "Epoch: 62 | train_loss: 0.4868 | train_acc: 0.7629 | test_loss: 1.0437 | test_acc: 0.5652\n",
            "Epoch: 63 | train_loss: 0.4071 | train_acc: 0.8454 | test_loss: 0.8140 | test_acc: 0.6087\n",
            "Epoch: 64 | train_loss: 0.4783 | train_acc: 0.7526 | test_loss: 0.9017 | test_acc: 0.5217\n",
            "Epoch: 65 | train_loss: 0.3935 | train_acc: 0.8144 | test_loss: 0.9273 | test_acc: 0.5652\n",
            "Epoch: 66 | train_loss: 0.4974 | train_acc: 0.7423 | test_loss: 0.9257 | test_acc: 0.5652\n",
            "Epoch: 67 | train_loss: 0.4668 | train_acc: 0.8144 | test_loss: 0.9339 | test_acc: 0.6087\n",
            "Epoch: 68 | train_loss: 0.4623 | train_acc: 0.7938 | test_loss: 1.0114 | test_acc: 0.5217\n",
            "Epoch: 69 | train_loss: 0.4469 | train_acc: 0.8351 | test_loss: 0.8977 | test_acc: 0.5652\n",
            "Epoch: 70 | train_loss: 0.4943 | train_acc: 0.7835 | test_loss: 0.7638 | test_acc: 0.5652\n",
            "Epoch: 71 | train_loss: 0.4655 | train_acc: 0.7526 | test_loss: 0.9710 | test_acc: 0.5217\n",
            "Epoch: 72 | train_loss: 0.4547 | train_acc: 0.7732 | test_loss: 1.1030 | test_acc: 0.4783\n",
            "Epoch: 73 | train_loss: 0.4846 | train_acc: 0.7732 | test_loss: 1.1537 | test_acc: 0.4348\n",
            "Epoch: 74 | train_loss: 0.4097 | train_acc: 0.7938 | test_loss: 1.2903 | test_acc: 0.5217\n",
            "Epoch: 75 | train_loss: 0.4775 | train_acc: 0.7526 | test_loss: 0.7791 | test_acc: 0.6522\n",
            "Epoch: 76 | train_loss: 0.4366 | train_acc: 0.8144 | test_loss: 1.0010 | test_acc: 0.6522\n",
            "Epoch: 77 | train_loss: 0.4444 | train_acc: 0.7938 | test_loss: 1.1100 | test_acc: 0.4348\n",
            "Epoch: 78 | train_loss: 0.4527 | train_acc: 0.7629 | test_loss: 0.8274 | test_acc: 0.6087\n",
            "Epoch: 79 | train_loss: 0.4109 | train_acc: 0.7732 | test_loss: 1.5485 | test_acc: 0.5652\n",
            "Epoch: 80 | train_loss: 0.3722 | train_acc: 0.8351 | test_loss: 1.1790 | test_acc: 0.5217\n",
            "Epoch: 81 | train_loss: 0.4680 | train_acc: 0.7629 | test_loss: 1.1331 | test_acc: 0.5217\n",
            "Epoch: 82 | train_loss: 0.3954 | train_acc: 0.8454 | test_loss: 1.2944 | test_acc: 0.4348\n",
            "Epoch: 83 | train_loss: 0.4261 | train_acc: 0.8351 | test_loss: 0.9428 | test_acc: 0.5217\n",
            "Epoch: 84 | train_loss: 0.4234 | train_acc: 0.8454 | test_loss: 1.0058 | test_acc: 0.3478\n",
            "Epoch: 85 | train_loss: 0.4176 | train_acc: 0.8247 | test_loss: 1.0220 | test_acc: 0.4783\n",
            "Epoch: 86 | train_loss: 0.4573 | train_acc: 0.7835 | test_loss: 0.8359 | test_acc: 0.5217\n",
            "Epoch: 87 | train_loss: 0.3991 | train_acc: 0.8144 | test_loss: 0.9402 | test_acc: 0.5217\n",
            "Epoch: 88 | train_loss: 0.3624 | train_acc: 0.8351 | test_loss: 0.9001 | test_acc: 0.4783\n",
            "Epoch: 89 | train_loss: 0.3842 | train_acc: 0.7938 | test_loss: 1.2571 | test_acc: 0.4348\n",
            "Epoch: 90 | train_loss: 0.4427 | train_acc: 0.7629 | test_loss: 1.1621 | test_acc: 0.5652\n",
            "Epoch: 91 | train_loss: 0.4530 | train_acc: 0.7629 | test_loss: 1.1106 | test_acc: 0.4783\n",
            "Epoch: 92 | train_loss: 0.4305 | train_acc: 0.8041 | test_loss: 1.1288 | test_acc: 0.4348\n",
            "Epoch: 93 | train_loss: 0.3728 | train_acc: 0.8454 | test_loss: 1.0708 | test_acc: 0.6522\n",
            "Epoch: 94 | train_loss: 0.3973 | train_acc: 0.8144 | test_loss: 1.1721 | test_acc: 0.4783\n",
            "Epoch: 95 | train_loss: 0.4074 | train_acc: 0.8454 | test_loss: 1.1863 | test_acc: 0.4783\n",
            "Epoch: 96 | train_loss: 0.3431 | train_acc: 0.8557 | test_loss: 1.0431 | test_acc: 0.5217\n",
            "Epoch: 97 | train_loss: 0.3333 | train_acc: 0.8660 | test_loss: 1.0964 | test_acc: 0.4348\n",
            "Epoch: 98 | train_loss: 0.4767 | train_acc: 0.7938 | test_loss: 0.9649 | test_acc: 0.4348\n",
            "Epoch: 99 | train_loss: 0.3873 | train_acc: 0.8454 | test_loss: 1.2680 | test_acc: 0.3913\n",
            "Epoch: 100 | train_loss: 0.4095 | train_acc: 0.8454 | test_loss: 1.0100 | test_acc: 0.6087\n",
            "Epoch: 101 | train_loss: 0.4361 | train_acc: 0.8247 | test_loss: 1.0581 | test_acc: 0.5652\n",
            "Epoch: 102 | train_loss: 0.3566 | train_acc: 0.8144 | test_loss: 0.9756 | test_acc: 0.4783\n",
            "Epoch: 103 | train_loss: 0.4353 | train_acc: 0.7938 | test_loss: 1.2577 | test_acc: 0.4783\n",
            "Epoch: 104 | train_loss: 0.4072 | train_acc: 0.8144 | test_loss: 1.2010 | test_acc: 0.4348\n",
            "Epoch: 105 | train_loss: 0.3552 | train_acc: 0.8557 | test_loss: 1.1265 | test_acc: 0.4348\n",
            "Epoch: 106 | train_loss: 0.3767 | train_acc: 0.8041 | test_loss: 1.1340 | test_acc: 0.6087\n",
            "Epoch: 107 | train_loss: 0.3686 | train_acc: 0.8247 | test_loss: 1.3357 | test_acc: 0.5217\n",
            "Epoch: 108 | train_loss: 0.4399 | train_acc: 0.7835 | test_loss: 0.9112 | test_acc: 0.3913\n",
            "Epoch: 109 | train_loss: 0.4153 | train_acc: 0.8247 | test_loss: 0.9772 | test_acc: 0.4783\n",
            "Epoch: 110 | train_loss: 0.3543 | train_acc: 0.8454 | test_loss: 0.8603 | test_acc: 0.6957\n",
            "Epoch: 111 | train_loss: 0.3934 | train_acc: 0.8041 | test_loss: 1.1102 | test_acc: 0.5652\n",
            "Epoch: 112 | train_loss: 0.4390 | train_acc: 0.8041 | test_loss: 1.1343 | test_acc: 0.5217\n",
            "Epoch: 113 | train_loss: 0.3976 | train_acc: 0.8247 | test_loss: 1.1369 | test_acc: 0.4348\n",
            "Epoch: 114 | train_loss: 0.3335 | train_acc: 0.8763 | test_loss: 1.5853 | test_acc: 0.3913\n",
            "Epoch: 115 | train_loss: 0.3726 | train_acc: 0.8351 | test_loss: 1.1857 | test_acc: 0.3478\n",
            "Epoch: 116 | train_loss: 0.3882 | train_acc: 0.8351 | test_loss: 1.1209 | test_acc: 0.5217\n",
            "Epoch: 117 | train_loss: 0.4158 | train_acc: 0.8247 | test_loss: 0.9845 | test_acc: 0.5217\n",
            "Epoch: 118 | train_loss: 0.4162 | train_acc: 0.7938 | test_loss: 1.2644 | test_acc: 0.4348\n",
            "Epoch: 119 | train_loss: 0.3653 | train_acc: 0.8247 | test_loss: 1.2881 | test_acc: 0.5217\n",
            "Epoch: 120 | train_loss: 0.3688 | train_acc: 0.8247 | test_loss: 1.2522 | test_acc: 0.5652\n",
            "Epoch: 121 | train_loss: 0.2916 | train_acc: 0.8866 | test_loss: 1.2624 | test_acc: 0.5217\n",
            "Epoch: 122 | train_loss: 0.3363 | train_acc: 0.8351 | test_loss: 1.0295 | test_acc: 0.4348\n",
            "Epoch: 123 | train_loss: 0.3448 | train_acc: 0.8351 | test_loss: 1.1139 | test_acc: 0.5652\n",
            "Epoch: 124 | train_loss: 0.3533 | train_acc: 0.8144 | test_loss: 1.3307 | test_acc: 0.5217\n",
            "Epoch: 125 | train_loss: 0.3345 | train_acc: 0.8866 | test_loss: 1.0345 | test_acc: 0.4783\n",
            "Epoch: 126 | train_loss: 0.3590 | train_acc: 0.8866 | test_loss: 0.9632 | test_acc: 0.6522\n",
            "Epoch: 127 | train_loss: 0.3205 | train_acc: 0.8763 | test_loss: 1.1148 | test_acc: 0.6087\n",
            "Epoch: 128 | train_loss: 0.3782 | train_acc: 0.8557 | test_loss: 1.2587 | test_acc: 0.5652\n",
            "Epoch: 129 | train_loss: 0.3712 | train_acc: 0.8763 | test_loss: 1.0641 | test_acc: 0.5652\n",
            "Epoch: 130 | train_loss: 0.3363 | train_acc: 0.8660 | test_loss: 1.2659 | test_acc: 0.5217\n",
            "Epoch: 131 | train_loss: 0.3684 | train_acc: 0.8247 | test_loss: 1.2128 | test_acc: 0.5652\n",
            "Epoch: 132 | train_loss: 0.3323 | train_acc: 0.8144 | test_loss: 1.0906 | test_acc: 0.6087\n",
            "Epoch: 133 | train_loss: 0.4197 | train_acc: 0.8969 | test_loss: 0.8514 | test_acc: 0.5652\n",
            "Epoch: 134 | train_loss: 0.3090 | train_acc: 0.8763 | test_loss: 1.0320 | test_acc: 0.6087\n",
            "Epoch: 135 | train_loss: 0.3373 | train_acc: 0.8351 | test_loss: 1.3006 | test_acc: 0.5652\n",
            "Epoch: 136 | train_loss: 0.3130 | train_acc: 0.8866 | test_loss: 1.1148 | test_acc: 0.4783\n",
            "Epoch: 137 | train_loss: 0.3524 | train_acc: 0.8041 | test_loss: 1.0323 | test_acc: 0.6087\n",
            "Epoch: 138 | train_loss: 0.3564 | train_acc: 0.8144 | test_loss: 1.2803 | test_acc: 0.4783\n",
            "Epoch: 139 | train_loss: 0.3158 | train_acc: 0.8866 | test_loss: 0.9322 | test_acc: 0.6957\n",
            "Epoch: 140 | train_loss: 0.3269 | train_acc: 0.8351 | test_loss: 1.1035 | test_acc: 0.3913\n",
            "Epoch: 141 | train_loss: 0.4086 | train_acc: 0.8351 | test_loss: 1.2506 | test_acc: 0.4783\n",
            "Epoch: 142 | train_loss: 0.3697 | train_acc: 0.8247 | test_loss: 1.1658 | test_acc: 0.4348\n",
            "Epoch: 143 | train_loss: 0.2858 | train_acc: 0.8763 | test_loss: 1.4035 | test_acc: 0.4783\n",
            "Epoch: 144 | train_loss: 0.3219 | train_acc: 0.8660 | test_loss: 1.4118 | test_acc: 0.4348\n",
            "Epoch: 145 | train_loss: 0.3332 | train_acc: 0.8144 | test_loss: 1.3158 | test_acc: 0.4783\n",
            "Epoch: 146 | train_loss: 0.2796 | train_acc: 0.8660 | test_loss: 0.7529 | test_acc: 0.6087\n",
            "Epoch: 147 | train_loss: 0.3120 | train_acc: 0.8763 | test_loss: 1.2214 | test_acc: 0.5217\n",
            "Epoch: 148 | train_loss: 0.3945 | train_acc: 0.7835 | test_loss: 0.9623 | test_acc: 0.6522\n",
            "Epoch: 149 | train_loss: 0.3229 | train_acc: 0.8660 | test_loss: 1.1513 | test_acc: 0.6957\n",
            "Epoch: 150 | train_loss: 0.2966 | train_acc: 0.8763 | test_loss: 1.4293 | test_acc: 0.4783\n",
            "Epoch: 151 | train_loss: 0.3741 | train_acc: 0.8557 | test_loss: 0.9492 | test_acc: 0.6522\n",
            "Epoch: 152 | train_loss: 0.2658 | train_acc: 0.9072 | test_loss: 1.3231 | test_acc: 0.5652\n",
            "Epoch: 153 | train_loss: 0.3654 | train_acc: 0.8144 | test_loss: 1.4705 | test_acc: 0.4783\n",
            "Epoch: 154 | train_loss: 0.3001 | train_acc: 0.8763 | test_loss: 1.2708 | test_acc: 0.6957\n",
            "Epoch: 155 | train_loss: 0.2657 | train_acc: 0.9072 | test_loss: 0.9797 | test_acc: 0.4783\n",
            "Epoch: 156 | train_loss: 0.3247 | train_acc: 0.8557 | test_loss: 1.1457 | test_acc: 0.4783\n",
            "Epoch: 157 | train_loss: 0.2642 | train_acc: 0.8866 | test_loss: 1.2678 | test_acc: 0.5217\n",
            "Epoch: 158 | train_loss: 0.3474 | train_acc: 0.8247 | test_loss: 1.2416 | test_acc: 0.5217\n",
            "Epoch: 159 | train_loss: 0.2570 | train_acc: 0.9175 | test_loss: 1.5238 | test_acc: 0.6087\n",
            "Epoch: 160 | train_loss: 0.2709 | train_acc: 0.8866 | test_loss: 1.7308 | test_acc: 0.5217\n",
            "Epoch: 161 | train_loss: 0.3413 | train_acc: 0.8557 | test_loss: 1.0795 | test_acc: 0.6087\n",
            "Epoch: 162 | train_loss: 0.2691 | train_acc: 0.8763 | test_loss: 1.6438 | test_acc: 0.5217\n",
            "Epoch: 163 | train_loss: 0.3328 | train_acc: 0.8454 | test_loss: 1.5549 | test_acc: 0.4348\n",
            "Epoch: 164 | train_loss: 0.3314 | train_acc: 0.8763 | test_loss: 1.0138 | test_acc: 0.5217\n",
            "Epoch: 165 | train_loss: 0.3268 | train_acc: 0.8454 | test_loss: 1.5397 | test_acc: 0.3478\n",
            "Epoch: 166 | train_loss: 0.2526 | train_acc: 0.8969 | test_loss: 1.4349 | test_acc: 0.4783\n",
            "Epoch: 167 | train_loss: 0.3876 | train_acc: 0.8247 | test_loss: 1.7647 | test_acc: 0.5652\n",
            "Epoch: 168 | train_loss: 0.3704 | train_acc: 0.8144 | test_loss: 1.4810 | test_acc: 0.4783\n",
            "Epoch: 169 | train_loss: 0.3244 | train_acc: 0.8763 | test_loss: 1.4228 | test_acc: 0.5652\n",
            "Epoch: 170 | train_loss: 0.3010 | train_acc: 0.8454 | test_loss: 1.3389 | test_acc: 0.4783\n",
            "Epoch: 171 | train_loss: 0.2532 | train_acc: 0.9072 | test_loss: 1.2825 | test_acc: 0.4783\n",
            "Epoch: 172 | train_loss: 0.2342 | train_acc: 0.9175 | test_loss: 1.4372 | test_acc: 0.6087\n",
            "Epoch: 173 | train_loss: 0.2538 | train_acc: 0.8763 | test_loss: 1.3101 | test_acc: 0.4348\n",
            "Epoch: 174 | train_loss: 0.3361 | train_acc: 0.9072 | test_loss: 1.3823 | test_acc: 0.4783\n",
            "Epoch: 175 | train_loss: 0.2622 | train_acc: 0.8866 | test_loss: 1.3490 | test_acc: 0.5652\n",
            "Epoch: 176 | train_loss: 0.2606 | train_acc: 0.8969 | test_loss: 1.4896 | test_acc: 0.4783\n",
            "Epoch: 177 | train_loss: 0.3267 | train_acc: 0.8454 | test_loss: 1.8838 | test_acc: 0.4783\n",
            "Epoch: 178 | train_loss: 0.2905 | train_acc: 0.8660 | test_loss: 1.4312 | test_acc: 0.6087\n",
            "Epoch: 179 | train_loss: 0.2675 | train_acc: 0.8351 | test_loss: 1.1756 | test_acc: 0.5652\n",
            "Epoch: 180 | train_loss: 0.2768 | train_acc: 0.8454 | test_loss: 1.9657 | test_acc: 0.3913\n",
            "Epoch: 181 | train_loss: 0.4074 | train_acc: 0.8144 | test_loss: 1.2814 | test_acc: 0.6087\n",
            "Epoch: 182 | train_loss: 0.3766 | train_acc: 0.7938 | test_loss: 1.2732 | test_acc: 0.6957\n",
            "Epoch: 183 | train_loss: 0.2284 | train_acc: 0.9278 | test_loss: 1.6856 | test_acc: 0.5217\n",
            "Epoch: 184 | train_loss: 0.2603 | train_acc: 0.8660 | test_loss: 1.0501 | test_acc: 0.4348\n",
            "Epoch: 185 | train_loss: 0.3014 | train_acc: 0.8557 | test_loss: 1.1341 | test_acc: 0.5217\n",
            "Epoch: 186 | train_loss: 0.2696 | train_acc: 0.8866 | test_loss: 2.1080 | test_acc: 0.5217\n",
            "Epoch: 187 | train_loss: 0.2977 | train_acc: 0.8660 | test_loss: 2.0490 | test_acc: 0.5652\n",
            "Epoch: 188 | train_loss: 0.3378 | train_acc: 0.8763 | test_loss: 1.2565 | test_acc: 0.6522\n",
            "Epoch: 189 | train_loss: 0.3959 | train_acc: 0.8351 | test_loss: 1.3132 | test_acc: 0.3913\n",
            "Epoch: 190 | train_loss: 0.2258 | train_acc: 0.9072 | test_loss: 1.3484 | test_acc: 0.4783\n",
            "Epoch: 191 | train_loss: 0.2261 | train_acc: 0.9072 | test_loss: 1.6482 | test_acc: 0.4783\n",
            "Epoch: 192 | train_loss: 0.3151 | train_acc: 0.9072 | test_loss: 1.2699 | test_acc: 0.5652\n",
            "Epoch: 193 | train_loss: 0.2253 | train_acc: 0.9175 | test_loss: 1.4447 | test_acc: 0.5217\n",
            "Epoch: 194 | train_loss: 0.2258 | train_acc: 0.9278 | test_loss: 1.4136 | test_acc: 0.4348\n",
            "Epoch: 195 | train_loss: 0.2096 | train_acc: 0.9072 | test_loss: 1.3906 | test_acc: 0.6087\n",
            "Epoch: 196 | train_loss: 0.2757 | train_acc: 0.8763 | test_loss: 1.6004 | test_acc: 0.3913\n",
            "Epoch: 197 | train_loss: 0.2846 | train_acc: 0.8763 | test_loss: 1.3323 | test_acc: 0.5652\n",
            "Epoch: 198 | train_loss: 0.3223 | train_acc: 0.8144 | test_loss: 1.4442 | test_acc: 0.5217\n",
            "Epoch: 199 | train_loss: 0.4348 | train_acc: 0.8351 | test_loss: 1.4904 | test_acc: 0.5217\n",
            "Epoch: 200 | train_loss: 0.2187 | train_acc: 0.9175 | test_loss: 1.4302 | test_acc: 0.3913\n",
            "Epoch: 201 | train_loss: 0.2145 | train_acc: 0.8763 | test_loss: 1.4150 | test_acc: 0.4348\n",
            "Epoch: 202 | train_loss: 0.2955 | train_acc: 0.8660 | test_loss: 1.2070 | test_acc: 0.6087\n",
            "Epoch: 203 | train_loss: 0.2535 | train_acc: 0.8969 | test_loss: 1.4121 | test_acc: 0.4783\n",
            "Epoch: 204 | train_loss: 0.2106 | train_acc: 0.9278 | test_loss: 1.4176 | test_acc: 0.4783\n",
            "Epoch: 205 | train_loss: 0.3208 | train_acc: 0.8454 | test_loss: 1.0792 | test_acc: 0.6087\n",
            "Epoch: 206 | train_loss: 0.2215 | train_acc: 0.9278 | test_loss: 1.7840 | test_acc: 0.4783\n",
            "Epoch: 207 | train_loss: 0.1739 | train_acc: 0.9072 | test_loss: 1.3416 | test_acc: 0.5652\n",
            "Epoch: 208 | train_loss: 0.2582 | train_acc: 0.8866 | test_loss: 1.1247 | test_acc: 0.5652\n",
            "Epoch: 209 | train_loss: 0.2191 | train_acc: 0.9072 | test_loss: 2.4730 | test_acc: 0.5217\n",
            "Epoch: 210 | train_loss: 0.2349 | train_acc: 0.9072 | test_loss: 1.5303 | test_acc: 0.5652\n",
            "Epoch: 211 | train_loss: 0.2230 | train_acc: 0.9278 | test_loss: 1.4775 | test_acc: 0.5217\n",
            "Epoch: 212 | train_loss: 0.3359 | train_acc: 0.8557 | test_loss: 1.4602 | test_acc: 0.3478\n",
            "Epoch: 213 | train_loss: 0.2025 | train_acc: 0.9072 | test_loss: 1.4244 | test_acc: 0.5217\n",
            "Epoch: 214 | train_loss: 0.2154 | train_acc: 0.9072 | test_loss: 1.5615 | test_acc: 0.5217\n",
            "Epoch: 215 | train_loss: 0.2059 | train_acc: 0.9072 | test_loss: 1.5209 | test_acc: 0.4783\n",
            "Epoch: 216 | train_loss: 0.2228 | train_acc: 0.9175 | test_loss: 1.8148 | test_acc: 0.5217\n",
            "Epoch: 217 | train_loss: 0.2556 | train_acc: 0.8866 | test_loss: 1.6735 | test_acc: 0.4348\n",
            "Epoch: 218 | train_loss: 0.1672 | train_acc: 0.9381 | test_loss: 1.6737 | test_acc: 0.4783\n",
            "Epoch: 219 | train_loss: 0.1915 | train_acc: 0.9485 | test_loss: 2.0061 | test_acc: 0.4348\n",
            "Epoch: 220 | train_loss: 0.2546 | train_acc: 0.8763 | test_loss: 1.3317 | test_acc: 0.3913\n",
            "Epoch: 221 | train_loss: 0.1537 | train_acc: 0.9588 | test_loss: 1.5895 | test_acc: 0.4348\n",
            "Epoch: 222 | train_loss: 0.2190 | train_acc: 0.9175 | test_loss: 1.5344 | test_acc: 0.4348\n",
            "Epoch: 223 | train_loss: 0.2503 | train_acc: 0.9175 | test_loss: 2.0023 | test_acc: 0.3478\n",
            "Epoch: 224 | train_loss: 0.1647 | train_acc: 0.9175 | test_loss: 1.9746 | test_acc: 0.4348\n",
            "Epoch: 225 | train_loss: 0.2104 | train_acc: 0.9175 | test_loss: 1.8728 | test_acc: 0.5217\n",
            "Epoch: 226 | train_loss: 0.2929 | train_acc: 0.8557 | test_loss: 2.7798 | test_acc: 0.5217\n",
            "Epoch: 227 | train_loss: 0.3085 | train_acc: 0.8557 | test_loss: 2.0342 | test_acc: 0.3913\n",
            "Epoch: 228 | train_loss: 0.2059 | train_acc: 0.8969 | test_loss: 2.1250 | test_acc: 0.5652\n",
            "Epoch: 229 | train_loss: 0.1373 | train_acc: 0.9381 | test_loss: 1.4139 | test_acc: 0.5217\n",
            "Epoch: 230 | train_loss: 0.2904 | train_acc: 0.8763 | test_loss: 1.8740 | test_acc: 0.4783\n",
            "Epoch: 231 | train_loss: 0.1826 | train_acc: 0.9485 | test_loss: 2.4666 | test_acc: 0.4783\n",
            "Epoch: 232 | train_loss: 0.2446 | train_acc: 0.9175 | test_loss: 1.6263 | test_acc: 0.4348\n",
            "Epoch: 233 | train_loss: 0.2045 | train_acc: 0.9175 | test_loss: 1.4369 | test_acc: 0.5652\n",
            "Epoch: 234 | train_loss: 0.2058 | train_acc: 0.9485 | test_loss: 1.8750 | test_acc: 0.5217\n",
            "Epoch: 235 | train_loss: 0.2495 | train_acc: 0.8969 | test_loss: 1.2856 | test_acc: 0.5652\n",
            "Epoch: 236 | train_loss: 0.2288 | train_acc: 0.9072 | test_loss: 1.3779 | test_acc: 0.4783\n",
            "Epoch: 237 | train_loss: 0.2073 | train_acc: 0.9278 | test_loss: 2.1902 | test_acc: 0.4783\n",
            "Epoch: 238 | train_loss: 0.2247 | train_acc: 0.9175 | test_loss: 2.3332 | test_acc: 0.4783\n",
            "Epoch: 239 | train_loss: 0.1857 | train_acc: 0.9588 | test_loss: 2.1764 | test_acc: 0.4783\n",
            "Epoch: 240 | train_loss: 0.1691 | train_acc: 0.9381 | test_loss: 1.7926 | test_acc: 0.5217\n",
            "Epoch: 241 | train_loss: 0.1473 | train_acc: 0.9485 | test_loss: 2.4992 | test_acc: 0.4348\n",
            "Epoch: 242 | train_loss: 0.1243 | train_acc: 0.9588 | test_loss: 1.7876 | test_acc: 0.4783\n",
            "Epoch: 243 | train_loss: 0.2482 | train_acc: 0.9381 | test_loss: 1.7445 | test_acc: 0.4348\n",
            "Epoch: 244 | train_loss: 0.1233 | train_acc: 0.9485 | test_loss: 2.0482 | test_acc: 0.4783\n",
            "Epoch: 245 | train_loss: 0.1944 | train_acc: 0.9381 | test_loss: 1.9058 | test_acc: 0.5652\n",
            "Epoch: 246 | train_loss: 0.1477 | train_acc: 0.9588 | test_loss: 1.7142 | test_acc: 0.6087\n",
            "Epoch: 247 | train_loss: 0.2223 | train_acc: 0.8866 | test_loss: 1.4708 | test_acc: 0.5217\n",
            "Epoch: 248 | train_loss: 0.1941 | train_acc: 0.8866 | test_loss: 1.9382 | test_acc: 0.5217\n",
            "Epoch: 249 | train_loss: 0.1702 | train_acc: 0.9381 | test_loss: 2.1055 | test_acc: 0.4348\n",
            "Epoch: 250 | train_loss: 0.1624 | train_acc: 0.9175 | test_loss: 2.0876 | test_acc: 0.5217\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_loss': [0.5743812395970231,\n",
              "  0.5514865643968901,\n",
              "  0.5609219374192744,\n",
              "  0.5693082119597449,\n",
              "  0.5844649460896388,\n",
              "  0.5791809073620543,\n",
              "  0.5430788053871737,\n",
              "  0.5761698553549874,\n",
              "  0.5440621442094291,\n",
              "  0.5414628091066614,\n",
              "  0.5696842328299644,\n",
              "  0.5862159935575094,\n",
              "  0.5439913166955728,\n",
              "  0.5655632352398843,\n",
              "  0.5338119324872789,\n",
              "  0.5120903970193618,\n",
              "  0.5268239961437804,\n",
              "  0.5471382071216082,\n",
              "  0.5547031386918628,\n",
              "  0.5370194090472669,\n",
              "  0.4982926305575469,\n",
              "  0.5459581075497836,\n",
              "  0.5320607334298572,\n",
              "  0.5478463916434455,\n",
              "  0.5294556242519433,\n",
              "  0.5110367648255503,\n",
              "  0.5166944772696372,\n",
              "  0.5441514288660946,\n",
              "  0.5320986892989615,\n",
              "  0.48060539450266004,\n",
              "  0.5181492249548589,\n",
              "  0.47361670858850796,\n",
              "  0.5345172392607657,\n",
              "  0.47975719487294555,\n",
              "  0.4862235737388435,\n",
              "  0.5205660975855035,\n",
              "  0.49954618383967075,\n",
              "  0.4937903800062336,\n",
              "  0.5063225520107434,\n",
              "  0.5246213478775522,\n",
              "  0.46185319962882504,\n",
              "  0.4770203634458066,\n",
              "  0.5235140219225174,\n",
              "  0.5018971941827499,\n",
              "  0.48387671832820955,\n",
              "  0.476681814994663,\n",
              "  0.4469774147332406,\n",
              "  0.4888705836426582,\n",
              "  0.46307799229566393,\n",
              "  0.5043366092506835,\n",
              "  0.4733252913532683,\n",
              "  0.464185223900281,\n",
              "  0.456256066612208,\n",
              "  0.4343334041876699,\n",
              "  0.48579782054077875,\n",
              "  0.4779887327674738,\n",
              "  0.4789445496178664,\n",
              "  0.4783613997338743,\n",
              "  0.428772913068821,\n",
              "  0.41733798440593806,\n",
              "  0.4117789528516875,\n",
              "  0.48676100286256674,\n",
              "  0.4071076879981118,\n",
              "  0.4782809037307143,\n",
              "  0.3934580355200955,\n",
              "  0.49737401007069754,\n",
              "  0.4668199885618566,\n",
              "  0.46225018143058594,\n",
              "  0.44693307537038224,\n",
              "  0.4943369435405685,\n",
              "  0.4654539555752861,\n",
              "  0.4546938660667403,\n",
              "  0.4845808200885004,\n",
              "  0.40974136578283976,\n",
              "  0.4774711139160496,\n",
              "  0.4365892900632858,\n",
              "  0.4444268261125676,\n",
              "  0.45267168690178056,\n",
              "  0.41086375047980817,\n",
              "  0.37217977270844016,\n",
              "  0.46796454828290734,\n",
              "  0.39539609206997167,\n",
              "  0.42611682332557693,\n",
              "  0.4234157249705924,\n",
              "  0.4176214840023097,\n",
              "  0.45725448373297095,\n",
              "  0.3991083871189459,\n",
              "  0.3624485179496276,\n",
              "  0.38417337152424186,\n",
              "  0.4426853452356395,\n",
              "  0.4530037272236665,\n",
              "  0.4304655281654031,\n",
              "  0.3728044967208485,\n",
              "  0.39727328643373805,\n",
              "  0.4073883683448321,\n",
              "  0.3430988679775913,\n",
              "  0.3333127588011473,\n",
              "  0.4767318001825881,\n",
              "  0.38734729946338925,\n",
              "  0.4094799151322131,\n",
              "  0.4361431461723807,\n",
              "  0.35663215800101994,\n",
              "  0.4352889106385098,\n",
              "  0.40723546978461883,\n",
              "  0.35518574634730127,\n",
              "  0.3767185296176827,\n",
              "  0.36855879769892763,\n",
              "  0.4398730830551958,\n",
              "  0.41534400826917733,\n",
              "  0.35431457936287303,\n",
              "  0.39343248383836193,\n",
              "  0.43898150563292154,\n",
              "  0.3976083173611843,\n",
              "  0.3335358967298591,\n",
              "  0.37262761298616265,\n",
              "  0.388219023058575,\n",
              "  0.41578639797395583,\n",
              "  0.4161766111845038,\n",
              "  0.3652778395572221,\n",
              "  0.36882230209561123,\n",
              "  0.2915587743093768,\n",
              "  0.33634555842814434,\n",
              "  0.3447620910312965,\n",
              "  0.35327824474263686,\n",
              "  0.33450201714761524,\n",
              "  0.35898280961581447,\n",
              "  0.32045201610275137,\n",
              "  0.37823319889280027,\n",
              "  0.37120696553587945,\n",
              "  0.336299896708446,\n",
              "  0.36842639487365453,\n",
              "  0.3323112820528961,\n",
              "  0.4197031199276812,\n",
              "  0.3089771936929631,\n",
              "  0.3373461697706215,\n",
              "  0.31297979539004633,\n",
              "  0.352431310582894,\n",
              "  0.35643639511087627,\n",
              "  0.31581186019808305,\n",
              "  0.326945400434908,\n",
              "  0.40857630742074125,\n",
              "  0.36966469349435915,\n",
              "  0.2857514107202302,\n",
              "  0.32192215208990616,\n",
              "  0.3331678955821152,\n",
              "  0.27959362619539835,\n",
              "  0.31196797316753533,\n",
              "  0.3944966674555956,\n",
              "  0.3228681004625099,\n",
              "  0.2965769385948976,\n",
              "  0.374076255151428,\n",
              "  0.26584603884554414,\n",
              "  0.3654286312263401,\n",
              "  0.30008075722915084,\n",
              "  0.2657145483137781,\n",
              "  0.3246830574923676,\n",
              "  0.2642038557864861,\n",
              "  0.3473791635018896,\n",
              "  0.2570480411616409,\n",
              "  0.27094984399887206,\n",
              "  0.3413351622487182,\n",
              "  0.26911638724417686,\n",
              "  0.3328010911270034,\n",
              "  0.3313684682174257,\n",
              "  0.32681519053551605,\n",
              "  0.2525619701987547,\n",
              "  0.387642856824266,\n",
              "  0.3704338076331811,\n",
              "  0.3244306094270401,\n",
              "  0.3010195941998431,\n",
              "  0.25318150860438593,\n",
              "  0.23423707929107399,\n",
              "  0.2537796336403179,\n",
              "  0.3361242832590374,\n",
              "  0.2622406033054823,\n",
              "  0.2606480716140984,\n",
              "  0.3267196196005542,\n",
              "  0.29049798626540896,\n",
              "  0.26751844445224726,\n",
              "  0.27683864106528716,\n",
              "  0.4074422098678717,\n",
              "  0.37658570005051967,\n",
              "  0.2284227174673809,\n",
              "  0.26028640675919923,\n",
              "  0.30143416489949065,\n",
              "  0.26964823436534885,\n",
              "  0.2977255027052303,\n",
              "  0.33777066801466504,\n",
              "  0.3958922184976154,\n",
              "  0.22580940117085888,\n",
              "  0.22611172428653462,\n",
              "  0.3150806813905125,\n",
              "  0.22531930350339377,\n",
              "  0.22579880120751694,\n",
              "  0.2095677229512964,\n",
              "  0.27568067368078514,\n",
              "  0.2846315453176412,\n",
              "  0.3223401088878595,\n",
              "  0.4347619815446318,\n",
              "  0.2187178509469131,\n",
              "  0.21451933407231372,\n",
              "  0.2954529927230822,\n",
              "  0.25348118304017836,\n",
              "  0.21064525905921572,\n",
              "  0.3208121596247781,\n",
              "  0.22151761455331992,\n",
              "  0.17388158702892106,\n",
              "  0.25819253509370554,\n",
              "  0.21907490935837315,\n",
              "  0.23490408428051993,\n",
              "  0.2229761971067858,\n",
              "  0.3359281196766944,\n",
              "  0.20254814346241903,\n",
              "  0.21544300164365543,\n",
              "  0.20593908731641172,\n",
              "  0.22284875766993154,\n",
              "  0.255579657354284,\n",
              "  0.16722004895084222,\n",
              "  0.19151438630221024,\n",
              "  0.2546107937991205,\n",
              "  0.1536710364053109,\n",
              "  0.2190402282651101,\n",
              "  0.2503323092302248,\n",
              "  0.16470283515875195,\n",
              "  0.21037474300084283,\n",
              "  0.29290220397592037,\n",
              "  0.3084927654261394,\n",
              "  0.20594563364107782,\n",
              "  0.13726348197025762,\n",
              "  0.2904236627207308,\n",
              "  0.18255420701023975,\n",
              "  0.2446052237123832,\n",
              "  0.20452013374895406,\n",
              "  0.2058389594097608,\n",
              "  0.24948763944633245,\n",
              "  0.22877331115815713,\n",
              "  0.20727052363238282,\n",
              "  0.22467516177816504,\n",
              "  0.18566546032856698,\n",
              "  0.16911598356635474,\n",
              "  0.1472808888953077,\n",
              "  0.12428593250886658,\n",
              "  0.24824172480361292,\n",
              "  0.12326873556162991,\n",
              "  0.19442642129214754,\n",
              "  0.1477083909168174,\n",
              "  0.22230461948348285,\n",
              "  0.19408598536794913,\n",
              "  0.17023951067756116,\n",
              "  0.16238141249661248],\n",
              " 'train_acc': [0.7216494845360825,\n",
              "  0.7010309278350515,\n",
              "  0.6907216494845361,\n",
              "  0.7010309278350515,\n",
              "  0.711340206185567,\n",
              "  0.6185567010309279,\n",
              "  0.7422680412371134,\n",
              "  0.7525773195876289,\n",
              "  0.7628865979381443,\n",
              "  0.7216494845360825,\n",
              "  0.711340206185567,\n",
              "  0.6804123711340206,\n",
              "  0.7319587628865979,\n",
              "  0.7422680412371134,\n",
              "  0.7319587628865979,\n",
              "  0.711340206185567,\n",
              "  0.7422680412371134,\n",
              "  0.7319587628865979,\n",
              "  0.7422680412371134,\n",
              "  0.7628865979381443,\n",
              "  0.7422680412371134,\n",
              "  0.711340206185567,\n",
              "  0.7422680412371134,\n",
              "  0.7319587628865979,\n",
              "  0.7628865979381443,\n",
              "  0.7628865979381443,\n",
              "  0.7938144329896907,\n",
              "  0.711340206185567,\n",
              "  0.7525773195876289,\n",
              "  0.7628865979381443,\n",
              "  0.7422680412371134,\n",
              "  0.7216494845360825,\n",
              "  0.7525773195876289,\n",
              "  0.7525773195876289,\n",
              "  0.7422680412371134,\n",
              "  0.7319587628865979,\n",
              "  0.7628865979381443,\n",
              "  0.7525773195876289,\n",
              "  0.711340206185567,\n",
              "  0.7525773195876289,\n",
              "  0.7835051546391752,\n",
              "  0.7319587628865979,\n",
              "  0.711340206185567,\n",
              "  0.7731958762886598,\n",
              "  0.7525773195876289,\n",
              "  0.7835051546391752,\n",
              "  0.7628865979381443,\n",
              "  0.7422680412371134,\n",
              "  0.8041237113402062,\n",
              "  0.7628865979381443,\n",
              "  0.7938144329896907,\n",
              "  0.7938144329896907,\n",
              "  0.7835051546391752,\n",
              "  0.8144329896907216,\n",
              "  0.7731958762886598,\n",
              "  0.7731958762886598,\n",
              "  0.7628865979381443,\n",
              "  0.7731958762886598,\n",
              "  0.8041237113402062,\n",
              "  0.7835051546391752,\n",
              "  0.8350515463917526,\n",
              "  0.7628865979381443,\n",
              "  0.845360824742268,\n",
              "  0.7525773195876289,\n",
              "  0.8144329896907216,\n",
              "  0.7422680412371134,\n",
              "  0.8144329896907216,\n",
              "  0.7938144329896907,\n",
              "  0.8350515463917526,\n",
              "  0.7835051546391752,\n",
              "  0.7525773195876289,\n",
              "  0.7731958762886598,\n",
              "  0.7731958762886598,\n",
              "  0.7938144329896907,\n",
              "  0.7525773195876289,\n",
              "  0.8144329896907216,\n",
              "  0.7938144329896907,\n",
              "  0.7628865979381443,\n",
              "  0.7731958762886598,\n",
              "  0.8350515463917526,\n",
              "  0.7628865979381443,\n",
              "  0.845360824742268,\n",
              "  0.8350515463917526,\n",
              "  0.845360824742268,\n",
              "  0.8247422680412371,\n",
              "  0.7835051546391752,\n",
              "  0.8144329896907216,\n",
              "  0.8350515463917526,\n",
              "  0.7938144329896907,\n",
              "  0.7628865979381443,\n",
              "  0.7628865979381443,\n",
              "  0.8041237113402062,\n",
              "  0.845360824742268,\n",
              "  0.8144329896907216,\n",
              "  0.845360824742268,\n",
              "  0.8556701030927835,\n",
              "  0.865979381443299,\n",
              "  0.7938144329896907,\n",
              "  0.845360824742268,\n",
              "  0.845360824742268,\n",
              "  0.8247422680412371,\n",
              "  0.8144329896907216,\n",
              "  0.7938144329896907,\n",
              "  0.8144329896907216,\n",
              "  0.8556701030927835,\n",
              "  0.8041237113402062,\n",
              "  0.8247422680412371,\n",
              "  0.7835051546391752,\n",
              "  0.8247422680412371,\n",
              "  0.845360824742268,\n",
              "  0.8041237113402062,\n",
              "  0.8041237113402062,\n",
              "  0.8247422680412371,\n",
              "  0.8762886597938144,\n",
              "  0.8350515463917526,\n",
              "  0.8350515463917526,\n",
              "  0.8247422680412371,\n",
              "  0.7938144329896907,\n",
              "  0.8247422680412371,\n",
              "  0.8247422680412371,\n",
              "  0.8865979381443299,\n",
              "  0.8350515463917526,\n",
              "  0.8350515463917526,\n",
              "  0.8144329896907216,\n",
              "  0.8865979381443299,\n",
              "  0.8865979381443299,\n",
              "  0.8762886597938144,\n",
              "  0.8556701030927835,\n",
              "  0.8762886597938144,\n",
              "  0.865979381443299,\n",
              "  0.8247422680412371,\n",
              "  0.8144329896907216,\n",
              "  0.8969072164948454,\n",
              "  0.8762886597938144,\n",
              "  0.8350515463917526,\n",
              "  0.8865979381443299,\n",
              "  0.8041237113402062,\n",
              "  0.8144329896907216,\n",
              "  0.8865979381443299,\n",
              "  0.8350515463917526,\n",
              "  0.8350515463917526,\n",
              "  0.8247422680412371,\n",
              "  0.8762886597938144,\n",
              "  0.865979381443299,\n",
              "  0.8144329896907216,\n",
              "  0.865979381443299,\n",
              "  0.8762886597938144,\n",
              "  0.7835051546391752,\n",
              "  0.865979381443299,\n",
              "  0.8762886597938144,\n",
              "  0.8556701030927835,\n",
              "  0.9072164948453608,\n",
              "  0.8144329896907216,\n",
              "  0.8762886597938144,\n",
              "  0.9072164948453608,\n",
              "  0.8556701030927835,\n",
              "  0.8865979381443299,\n",
              "  0.8247422680412371,\n",
              "  0.9175257731958762,\n",
              "  0.8865979381443299,\n",
              "  0.8556701030927835,\n",
              "  0.8762886597938144,\n",
              "  0.845360824742268,\n",
              "  0.8762886597938144,\n",
              "  0.845360824742268,\n",
              "  0.8969072164948454,\n",
              "  0.8247422680412371,\n",
              "  0.8144329896907216,\n",
              "  0.8762886597938144,\n",
              "  0.845360824742268,\n",
              "  0.9072164948453608,\n",
              "  0.9175257731958762,\n",
              "  0.8762886597938144,\n",
              "  0.9072164948453608,\n",
              "  0.8865979381443299,\n",
              "  0.8969072164948454,\n",
              "  0.845360824742268,\n",
              "  0.865979381443299,\n",
              "  0.8350515463917526,\n",
              "  0.845360824742268,\n",
              "  0.8144329896907216,\n",
              "  0.7938144329896907,\n",
              "  0.9278350515463918,\n",
              "  0.865979381443299,\n",
              "  0.8556701030927835,\n",
              "  0.8865979381443299,\n",
              "  0.865979381443299,\n",
              "  0.8762886597938144,\n",
              "  0.8350515463917526,\n",
              "  0.9072164948453608,\n",
              "  0.9072164948453608,\n",
              "  0.9072164948453608,\n",
              "  0.9175257731958762,\n",
              "  0.9278350515463918,\n",
              "  0.9072164948453608,\n",
              "  0.8762886597938144,\n",
              "  0.8762886597938144,\n",
              "  0.8144329896907216,\n",
              "  0.8350515463917526,\n",
              "  0.9175257731958762,\n",
              "  0.8762886597938144,\n",
              "  0.865979381443299,\n",
              "  0.8969072164948454,\n",
              "  0.9278350515463918,\n",
              "  0.845360824742268,\n",
              "  0.9278350515463918,\n",
              "  0.9072164948453608,\n",
              "  0.8865979381443299,\n",
              "  0.9072164948453608,\n",
              "  0.9072164948453608,\n",
              "  0.9278350515463918,\n",
              "  0.8556701030927835,\n",
              "  0.9072164948453608,\n",
              "  0.9072164948453608,\n",
              "  0.9072164948453608,\n",
              "  0.9175257731958762,\n",
              "  0.8865979381443299,\n",
              "  0.9381443298969072,\n",
              "  0.9484536082474226,\n",
              "  0.8762886597938144,\n",
              "  0.9587628865979382,\n",
              "  0.9175257731958762,\n",
              "  0.9175257731958762,\n",
              "  0.9175257731958762,\n",
              "  0.9175257731958762,\n",
              "  0.8556701030927835,\n",
              "  0.8556701030927835,\n",
              "  0.8969072164948454,\n",
              "  0.9381443298969072,\n",
              "  0.8762886597938144,\n",
              "  0.9484536082474226,\n",
              "  0.9175257731958762,\n",
              "  0.9175257731958762,\n",
              "  0.9484536082474226,\n",
              "  0.8969072164948454,\n",
              "  0.9072164948453608,\n",
              "  0.9278350515463918,\n",
              "  0.9175257731958762,\n",
              "  0.9587628865979382,\n",
              "  0.9381443298969072,\n",
              "  0.9484536082474226,\n",
              "  0.9587628865979382,\n",
              "  0.9381443298969072,\n",
              "  0.9484536082474226,\n",
              "  0.9381443298969072,\n",
              "  0.9587628865979382,\n",
              "  0.8865979381443299,\n",
              "  0.8865979381443299,\n",
              "  0.9381443298969072,\n",
              "  0.9175257731958762],\n",
              " 'test_loss': [0.8753687532051749,\n",
              "  0.8005081431373305,\n",
              "  0.741275530308485,\n",
              "  0.770027682185173,\n",
              "  0.7059768486929976,\n",
              "  0.699270271088766,\n",
              "  0.9925397308543324,\n",
              "  0.7567437679871268,\n",
              "  0.8902102475580962,\n",
              "  0.7934241715980612,\n",
              "  0.9896967819203502,\n",
              "  0.8141940417497054,\n",
              "  0.7523884047632632,\n",
              "  0.8189698684474697,\n",
              "  0.9079469928274984,\n",
              "  0.9885254017198863,\n",
              "  0.944619123297541,\n",
              "  0.8487518842777481,\n",
              "  0.7467681700768678,\n",
              "  0.8137690580409506,\n",
              "  0.9479741842850394,\n",
              "  0.8891907826713894,\n",
              "  0.8725202465834825,\n",
              "  0.8095525107953859,\n",
              "  0.83106421744046,\n",
              "  0.7993924629105174,\n",
              "  0.8780748508870602,\n",
              "  0.8416582799476126,\n",
              "  0.8237574845552444,\n",
              "  0.8808961777097505,\n",
              "  0.6712228004699168,\n",
              "  0.9999374290523322,\n",
              "  0.9328171211578276,\n",
              "  0.8968442932338171,\n",
              "  0.864788367777415,\n",
              "  0.900357270370359,\n",
              "  0.8469685154926517,\n",
              "  1.0117744778728355,\n",
              "  0.7966521949628773,\n",
              "  0.6908595865673345,\n",
              "  1.1258087410672528,\n",
              "  0.9011329984211404,\n",
              "  0.9424084948132867,\n",
              "  0.9488620895730413,\n",
              "  0.9868042641116873,\n",
              "  0.8181693902158219,\n",
              "  0.9883209966609011,\n",
              "  0.7783786967072798,\n",
              "  0.9386173492783437,\n",
              "  0.9511103555965035,\n",
              "  0.9151528454993082,\n",
              "  0.7485448513989863,\n",
              "  1.2035077200068727,\n",
              "  0.85409466954677,\n",
              "  0.95302674603527,\n",
              "  0.9338436056252407,\n",
              "  0.754515066034282,\n",
              "  1.0126988298219184,\n",
              "  0.8864186804579652,\n",
              "  0.9612649434813015,\n",
              "  0.9688912369513317,\n",
              "  1.043680500967995,\n",
              "  0.8139980762549068,\n",
              "  0.9017320461976139,\n",
              "  0.9273129141201144,\n",
              "  0.9256816322145902,\n",
              "  0.933898537784167,\n",
              "  1.011419498483124,\n",
              "  0.8976988332427066,\n",
              "  0.7638473685668863,\n",
              "  0.9709935919179217,\n",
              "  1.1030266461488993,\n",
              "  1.1536930323294972,\n",
              "  1.2903355234909966,\n",
              "  0.7791448944936628,\n",
              "  1.0009877325400063,\n",
              "  1.1100195558822674,\n",
              "  0.8274039942771196,\n",
              "  1.5484719652854635,\n",
              "  1.179031021407117,\n",
              "  1.1330555243336635,\n",
              "  1.294405810372985,\n",
              "  0.9427625680261332,\n",
              "  1.005802497267723,\n",
              "  1.0220156278785155,\n",
              "  0.8358959706257219,\n",
              "  0.94023180493842,\n",
              "  0.9001453067378505,\n",
              "  1.257089577878461,\n",
              "  1.1621228511566701,\n",
              "  1.1106321096582257,\n",
              "  1.1287514855680258,\n",
              "  1.0708221417406332,\n",
              "  1.1721407640016759,\n",
              "  1.186298699968535,\n",
              "  1.0430577123922335,\n",
              "  1.0963650085031986,\n",
              "  0.9649103201277878,\n",
              "  1.2680306621503248,\n",
              "  1.0099575789442852,\n",
              "  1.0580868769599043,\n",
              "  0.9755707432961335,\n",
              "  1.2576692127825126,\n",
              "  1.2010047798166457,\n",
              "  1.1264777394092602,\n",
              "  1.134038971094212,\n",
              "  1.335728859508653,\n",
              "  0.9112268313765526,\n",
              "  0.97719288998,\n",
              "  0.8602624186517104,\n",
              "  1.110225944172429,\n",
              "  1.1343117808194265,\n",
              "  1.1369053902630897,\n",
              "  1.5853238630149027,\n",
              "  1.1857394157382457,\n",
              "  1.1208601694392122,\n",
              "  0.984492427305035,\n",
              "  1.2643780950254395,\n",
              "  1.2880977370457358,\n",
              "  1.2522437130303488,\n",
              "  1.2623613069805761,\n",
              "  1.0295356650148397,\n",
              "  1.1138838727998992,\n",
              "  1.3306940932272244,\n",
              "  1.0344671568144923,\n",
              "  0.9631505274497296,\n",
              "  1.1147570384023509,\n",
              "  1.258661299954047,\n",
              "  1.0640965860498988,\n",
              "  1.2659303168563738,\n",
              "  1.2127953040737496,\n",
              "  1.0906030151755144,\n",
              "  0.85143525817472,\n",
              "  1.0319581346019455,\n",
              "  1.3005766444232152,\n",
              "  1.1148392267565688,\n",
              "  1.0322759306139273,\n",
              "  1.2802808322214887,\n",
              "  0.9321965192414253,\n",
              "  1.1034799900067889,\n",
              "  1.2505870421933334,\n",
              "  1.1658049084894035,\n",
              "  1.4034651907707525,\n",
              "  1.4118272563994296,\n",
              "  1.3158331429180892,\n",
              "  0.7529330808750313,\n",
              "  1.2213696755630814,\n",
              "  0.9623335801550875,\n",
              "  1.151311642733281,\n",
              "  1.4292800331452822,\n",
              "  0.949169413793994,\n",
              "  1.3231499547887917,\n",
              "  1.4705346341234753,\n",
              "  1.2708297572908518,\n",
              "  0.9797002442343079,\n",
              "  1.1456934031018096,\n",
              "  1.267821321997832,\n",
              "  1.2415905445814133,\n",
              "  1.5238272817653564,\n",
              "  1.730799070520472,\n",
              "  1.0794833777573607,\n",
              "  1.6438394927490267,\n",
              "  1.5549192405052725,\n",
              "  1.0137875762808581,\n",
              "  1.5397310133456537,\n",
              "  1.4348501950684611,\n",
              "  1.7647230255812325,\n",
              "  1.480990523715382,\n",
              "  1.4228307970738767,\n",
              "  1.3389026806892261,\n",
              "  1.2824823921748802,\n",
              "  1.4372347975959596,\n",
              "  1.3100590747173713,\n",
              "  1.3823195119924925,\n",
              "  1.3489755401691503,\n",
              "  1.4895911595743636,\n",
              "  1.88379992336875,\n",
              "  1.4311633926978253,\n",
              "  1.1755530261232152,\n",
              "  1.9656963298595813,\n",
              "  1.2813513848687643,\n",
              "  1.2732431299215101,\n",
              "  1.685550053452101,\n",
              "  1.0501151565745797,\n",
              "  1.1341275607498928,\n",
              "  2.108023672905129,\n",
              "  2.049019366449616,\n",
              "  1.2565151129079901,\n",
              "  1.3131658518383198,\n",
              "  1.348371327996416,\n",
              "  1.6482444296327785,\n",
              "  1.2699105298025128,\n",
              "  1.444716191967018,\n",
              "  1.4136061021911346,\n",
              "  1.390635003836866,\n",
              "  1.6004054800647756,\n",
              "  1.3322818626285247,\n",
              "  1.4441947284959378,\n",
              "  1.4904354730539995,\n",
              "  1.430187193656583,\n",
              "  1.4150118271455816,\n",
              "  1.2070232144880877,\n",
              "  1.412063887950195,\n",
              "  1.4175998527080873,\n",
              "  1.07915973653207,\n",
              "  1.7840437221507865,\n",
              "  1.3415557645544733,\n",
              "  1.1247389013271616,\n",
              "  2.4729778605639656,\n",
              "  1.5303108187027923,\n",
              "  1.4775436833115236,\n",
              "  1.460196898440304,\n",
              "  1.4243986627831042,\n",
              "  1.5615168018671481,\n",
              "  1.5209246130822145,\n",
              "  1.8148492898921098,\n",
              "  1.6734622957276017,\n",
              "  1.6737266248750056,\n",
              "  2.006123985756067,\n",
              "  1.331743577869771,\n",
              "  1.589457850331319,\n",
              "  1.5343776545689807,\n",
              "  2.0023108000168577,\n",
              "  1.9746217076893158,\n",
              "  1.872846945042155,\n",
              "  2.77977616877201,\n",
              "  2.03415737840924,\n",
              "  2.125025084011925,\n",
              "  1.413868112762904,\n",
              "  1.8739684602529134,\n",
              "  2.4665843019256894,\n",
              "  1.626287558419711,\n",
              "  1.4369147011564802,\n",
              "  1.8750121704854437,\n",
              "  1.2856356374667604,\n",
              "  1.3778713690825617,\n",
              "  2.1902126426941084,\n",
              "  2.333198793760897,\n",
              "  2.176355134070669,\n",
              "  1.7926332124954332,\n",
              "  2.4991602890194096,\n",
              "  1.7876098546586707,\n",
              "  1.744528889021477,\n",
              "  2.0481613371869214,\n",
              "  1.9058023869014427,\n",
              "  1.7141853737019752,\n",
              "  1.470799417270309,\n",
              "  1.938241270016474,\n",
              "  2.105544479977613,\n",
              "  2.0876224848243115],\n",
              " 'test_acc': [0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.5652173913043478,\n",
              "  0.6086956521739131,\n",
              "  0.43478260869565216,\n",
              "  0.4782608695652174,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.6086956521739131,\n",
              "  0.6086956521739131,\n",
              "  0.5652173913043478,\n",
              "  0.7391304347826086,\n",
              "  0.5217391304347826,\n",
              "  0.4782608695652174,\n",
              "  0.5217391304347826,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.6086956521739131,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.6086956521739131,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.5652173913043478,\n",
              "  0.5652173913043478,\n",
              "  0.43478260869565216,\n",
              "  0.4782608695652174,\n",
              "  0.5217391304347826,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.6086956521739131,\n",
              "  0.6086956521739131,\n",
              "  0.5652173913043478,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.6521739130434783,\n",
              "  0.4782608695652174,\n",
              "  0.5217391304347826,\n",
              "  0.6956521739130435,\n",
              "  0.43478260869565216,\n",
              "  0.5652173913043478,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.5652173913043478,\n",
              "  0.5652173913043478,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.5652173913043478,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.5217391304347826,\n",
              "  0.6521739130434783,\n",
              "  0.6521739130434783,\n",
              "  0.43478260869565216,\n",
              "  0.6086956521739131,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.5217391304347826,\n",
              "  0.34782608695652173,\n",
              "  0.4782608695652174,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.6521739130434783,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.43478260869565216,\n",
              "  0.391304347826087,\n",
              "  0.6086956521739131,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.43478260869565216,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.391304347826087,\n",
              "  0.4782608695652174,\n",
              "  0.6956521739130435,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.391304347826087,\n",
              "  0.34782608695652173,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.5217391304347826,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.4782608695652174,\n",
              "  0.6521739130434783,\n",
              "  0.6086956521739131,\n",
              "  0.5652173913043478,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.5652173913043478,\n",
              "  0.6086956521739131,\n",
              "  0.5652173913043478,\n",
              "  0.6086956521739131,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.6086956521739131,\n",
              "  0.4782608695652174,\n",
              "  0.6956521739130435,\n",
              "  0.391304347826087,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.4782608695652174,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.6521739130434783,\n",
              "  0.6956521739130435,\n",
              "  0.4782608695652174,\n",
              "  0.6521739130434783,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.6956521739130435,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.5217391304347826,\n",
              "  0.34782608695652173,\n",
              "  0.4782608695652174,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.6086956521739131,\n",
              "  0.43478260869565216,\n",
              "  0.4782608695652174,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.6086956521739131,\n",
              "  0.5652173913043478,\n",
              "  0.391304347826087,\n",
              "  0.6086956521739131,\n",
              "  0.6956521739130435,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.5652173913043478,\n",
              "  0.6521739130434783,\n",
              "  0.391304347826087,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.6086956521739131,\n",
              "  0.391304347826087,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.391304347826087,\n",
              "  0.43478260869565216,\n",
              "  0.6086956521739131,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.6086956521739131,\n",
              "  0.4782608695652174,\n",
              "  0.5652173913043478,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.34782608695652173,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.4782608695652174,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.391304347826087,\n",
              "  0.43478260869565216,\n",
              "  0.43478260869565216,\n",
              "  0.34782608695652173,\n",
              "  0.43478260869565216,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.391304347826087,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.5652173913043478,\n",
              "  0.5217391304347826,\n",
              "  0.5652173913043478,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.4782608695652174,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.4782608695652174,\n",
              "  0.43478260869565216,\n",
              "  0.4782608695652174,\n",
              "  0.5652173913043478,\n",
              "  0.6086956521739131,\n",
              "  0.5217391304347826,\n",
              "  0.5217391304347826,\n",
              "  0.43478260869565216,\n",
              "  0.5217391304347826]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train(model, train_loader, test_loader, optimizer, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-oXLE9yb26V",
        "outputId": "4cf4be66-3c8a-4359-9432-654dc7e85602"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('AdClassificationModel/AdDetection.pt')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "Model_path = Path(\"AdClassificationModel\")\n",
        "Model_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "Model_Name  = \"AdDetection.pt\"\n",
        "\n",
        "SaveModelPath = Model_path / Model_Name\n",
        "\n",
        "SaveModelPath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bX4D5uIhb26W"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), SaveModelPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqoVf84Ub26W",
        "outputId": "d3e5a731-20da-4ffd-a8bf-0f2c7976f91e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 250, 250]), torch.Size([3, 1020, 736]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread(r\"/content/drive/MyDrive/AdClassification/Ad_Classification/train/Creative/Corona.jpeg\")\n",
        "pic = Image.open(r\"/content/drive/MyDrive/AdClassification/Ad_Classification/train/Creative/Corona.jpeg\")\n",
        "test_image = train_transform(pic)\n",
        "\n",
        "\n",
        "test_image.shape, sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imported = model\n",
        "\n",
        "imported.load_state_dict(torch.load(SaveModelPath))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvSXjxj2mPFX",
        "outputId": "350a751b-cdba-49ec-b3ac-4d624e19a751"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVSAfBDxb26W",
        "outputId": "4ef8d5c2-09ff-41ac-cdb6-426026064318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "imported.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    loaded_pred = imported(test_image.unsqueeze(dim =0))\n",
        "    pred_class = torch.argmax(torch.softmax(loaded_pred, dim =1), dim =1)\n",
        "pred_class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28MFWlhAb26W"
      },
      "outputs": [],
      "source": [
        "\n",
        "#& Strategies to Improve the Misclassifications\n",
        "\n",
        "\"\"\"\n",
        "1. Increasing the data size will reduce the misclassification\n",
        "2. Data Augmentation - In the above code we can include some more transformations.\n",
        "   This can be using torchvision.transforms function.This can be implemented in the\n",
        "   above coding\n",
        "3. Rather than going for custom model, we can go for Transfer Learning. We can take\n",
        "   Pre-trained model like VGG, Mobilenet etc.\n",
        "4. We can use learning rate decay\n",
        "5. Early Stopping - This will help us stop the training process when the training reaches\n",
        "   required amount of loss and   accuracy.\n",
        "6. Add More units of Sequential Layers Blocks, Increase the number of hidden layers,\n",
        "   Change the activation functions.\n",
        "7. Tweak Learning Rate migh also help achieve the goal\n",
        "8. Vary the Epoch sizes - Increasing the Epoch size shall help the model find the global minima.\n",
        "\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0eb078fb6a5b400eaef2df17ad3a98a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbe9238a0f3f4008811cb1a9701acaf6",
              "IPY_MODEL_5002e9e0a6564118b71d593472797254",
              "IPY_MODEL_390d2e6695fb4bdf9061e8da785cbe6e"
            ],
            "layout": "IPY_MODEL_fd4b53be5fbe4021b1a32c18ef951427"
          }
        },
        "cbe9238a0f3f4008811cb1a9701acaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cfac7a3b2ef4d75a2f682a7d1a6b1a1",
            "placeholder": "​",
            "style": "IPY_MODEL_729c347bc0404f49bb14569eaba16401",
            "value": "100%"
          }
        },
        "5002e9e0a6564118b71d593472797254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1424a6d79f224ccc973e1e975681f889",
            "max": 250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a1ce453518c407f807b1febbb9b1f05",
            "value": 250
          }
        },
        "390d2e6695fb4bdf9061e8da785cbe6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab6033643994b25959c23fe9c76b206",
            "placeholder": "​",
            "style": "IPY_MODEL_7f0902bf77264c9a8807b804c00a3860",
            "value": " 250/250 [17:32&lt;00:00,  4.13s/it]"
          }
        },
        "fd4b53be5fbe4021b1a32c18ef951427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cfac7a3b2ef4d75a2f682a7d1a6b1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729c347bc0404f49bb14569eaba16401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1424a6d79f224ccc973e1e975681f889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a1ce453518c407f807b1febbb9b1f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aab6033643994b25959c23fe9c76b206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f0902bf77264c9a8807b804c00a3860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}